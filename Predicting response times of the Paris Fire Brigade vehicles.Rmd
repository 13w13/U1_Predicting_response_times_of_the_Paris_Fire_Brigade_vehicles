---
title: "Predicting response times of the Paris Fire Brigade vehicles"
author: "Edgar Jullien, Antoine Settelen, Simon Weiss"
date: '`r Sys.Date()`'

output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
---


Liens notebook inspiration artistique : 
Les notebooks qui ont déja fait le challenge : 
https://github.com/quachn/X_PFB
https://github.com/Gguinet/Fire-Brigade-Challenge/blob/master/.ipynb_checkpoints/Code-checkpoint.ipynb




Les notebooks traintant du même type de problème : 
https://medium.com/crim/predicting-the-response-times-of-firefighters-using-data-science-da79f6965f93
https://www.kaggle.com/gaborfodor/from-eda-to-the-top-lb-0-367
https://www.kaggle.com/karelrv/nyct-from-a-to-z-with-xgboost-tutorial
https://www.kaggle.com/headsortails/nyc-taxi-eda-update-the-fast-the-curious


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

## Presentation of the project

This group project responds to the **prof Nadine Galy instructions** written below :  
The project involves identifying a real-world business problem or opportunity and designing and implementing an analysis plan to address it using at least one of the modelling methods studied in the course. You are free to choose any business problem or opportunity or public policy issue that you consider challenging and useful to address using business analytics.
The data that you use should be readily available and verifiable.

This is a notebook for the [Paris Fire Brigate](https://paris-fire-brigade.github.io/data-challenge/challenge.html) data challenge 2020 with [ENS](https://challengedata.ens.fr/participants/challenges/21/) and [College de France](https://www.college-de-france.fr/site/stephane-mallat/Challenges-2020.htm).


**The goal of this playground challenge** is to predict the *The response times of the Paris Fire Brigade vehicles * which is the delay between:
* the selection of a rescue vehicle (the time when a rescue team is warned) 
* and the rescue team arrival time at the scene of the request (information sent manually via portable radio)

This measurement is composed by the 2 following periods of time: 
* the activation period of the rescue team 
* the transit time of the rescue team

Based on features like trip coordinates, pickup date, type of the arriavl destination, vehicules etc.. 

The [data](https://challengedata.ens.fr/participants/challenges/21/) which covers the entier year 2018 for which inoperable data have been squeezed out comes in the shape of 219 337 training observations and 108 033 test observation. The dataset covers the entire year 
Each row contains one Paris fire brigade intervention.

"Response time is one of the most important factors for firefighters because their ability to save lives and rescue people depends on it. Every fire department in the world seeks strategies to decrease their response time, and several analyses have been conducted in the past years to determine what could impact response time. In the meantime, fire departments have been collecting data on their interventions; yet, few of them actually use data science to develop a data-driven decision making approach."https://medium.com/crim/predicting-the-response-times-of-firefighters-using-data-science-da79f6965f93


"A lot of fire departments and emergency services rely on geographic information systems tools, such as ESRI ARCGis or Network Analyst, to obtain estimations about the response time. These tools rely on computing the shortest route using a graphical representation of the road network, which usually gives an accurate estimate of the travel time. Their drawback is that they cannot always take into consideration external dynamic factors such as the weather, traffic or type of units or intervention. Hence, there is an opportunity for machine learning tools to be used here."



**In this notebook**, we will first study and visualise the original data, engineer new features, and examine potential outliers. Then... 

We hope that this notebook will have good results to the challenge and responds fully to Nadine Galy requirement.
As always, any feedback, questions, or constructive criticism are much appreciated.


## Features description


**Input parameters (x_train.csv and x_test.csv):**

* **[ID]** `emergency vehicle selection`: identifier of the selection instance of an emergency vehicle for an intervention
* Intervention
    * `intervention`: identifier of the intervention
    * Alert reason
        * `alert reason category` (category): alert reason category
        * `alert reason` (category): alert reason
    * Address
        * `intervention on public roads` (boolean): 1 when it concerns an intervention on public roads, 0 otherwise
        * `floor` (int): floor of the intervention
        * `location of the event` (category): qualifies the location of the emergency request, for example: entrance hall, boiler room, motorway, etc.
        * `longitude intervention` (float): approximate longitude of the intervention address. **ATTENTION: `intervention_longitude`** !
        * `latitude intervention` (float): approximate latitude of the intervention address. **ATTENTION: `intervention_latitude`** !
    * Emergency vehicle
        * `emergency vehicle`: identifier of the emergency vehicle
            * `emergency vehicle type` (category): type of the emergency vehicle
            * `rescue center` (category): identifier of the rescue center to which belong the vehicle (parking spot of the emergency vehicle)
        * `selection time` (datetime): selection time of the emergency vehicle
            * `date key selection` (int): selection date in YYYYMMDD format
            * `time key selection` (int): selection time in HHMMSS format
        * State of the emergency vehicle preceding its selection for an intervention
            * Operational status of the vehicle preceding its selection
                * `status preceding selection` (category): status of the emergency vehicle prior to selection. An emergency vehicle is in various statuses during an intervention:
                    * **Selection** - selection of the emergency vehicle by the rescue commitment application
                    * **Departed** - the vehicle starts its route to the location of the emergency request
                    * **Presented** - the vehicle arrives at the location of the request
                    * **Hospital transportation** - the vehicle starts its transport of a victim to hospital
                    * **Hospital arrival** - the vehicle arrives at the hospital
                    * **Leaving hospital** - the vehicle leaves the hospital
                    * **Returned** - the vehicle has returned to its parking spot
                    * **Leave the premises** - because the vehicle can also simply leave the scene of an intervention without having to transport any victim
                    * **Not available** - for various reasons the vehicle can be in an unavailable position
                    * **Not relevant** - statutes without interest
                * `delta status preceding selection-selection` (int): number of seconds before the vehicle was selected when its previous status was entered
            * `departed from its rescue center` (boolean) : 1 when the vehicle departed from its rescue center (emergency vehicle parking spot), 0 otherwise
            * GPS position of the vehicle before departure
                * `longitude before departure` (float): longitude of the position of the vehicle preceding his departure. **ATTENTION: `departure_longitude`** !
                * `latitude previous departure` (float): latitude of the position of the vehicle preceding his departure. **ATTENTION: `departure_latitude`** !
                * `delta position gps previous departure-departure` (int): number of seconds before the selection of the vehicle where its GPS position was recorded (when not parked at its emergency center)
            * GPS tracks
                * `GPS tracks departure-presentation` (float pair list): successive GPS positions (*longitude,latitude;longitude,latitude,* etc.) of the vehicle between departure and presentation. This information is for informational purposes to study vehicle behaviors. (The beacons, emitting the GPS positions of vehicles, are currently not always lit)
                * `GPS tracks departure-presentation datetime` (datetime list): datetime associated with successive GPS positions between the departure and the presentation of the vehicle.
            * Estimated route
                * `OSRM estimated route` (json object): service route response of an OSRM instance (http://project-osrm.org/docs/v5.15.2/api/#route-service) setup with the Ile-de-France OpenStreetMap data
                * `OSRM estimated distance` (float): distance calculated by the OSRM route service
                * `OSRM estimated duration` (float): transit delay calculated by the OSRM route service

**Output parameters (y_train.csv and y_test.csv):**

* **[ID]** `emergency vehicle selection`: identifier of the selection instance of an emergency vehicle for an intervention
* **[TO PREDICT]** `delta selection-departure`(int): elapsed time in seconds between the selection and the departure of the emergency vehicle
* **[TO PREDICT]** `delta departure-presentation`(int): elapsed time in seconds between the departure of the emergency vehicle and its presentation on the intervention scene
* **[TO PREDICT]** `delta selection-presentation `(int): elapsed time in seconds between the selection of the emergency vehicle and its presentation on the intervention scene (delta selection-departure + delta departure-presentation)



**Supplementary files (x_train_additional_file.csv and x_test_additional_file.csv)**

* **[ID]** `emergency vehicle selection`: identifier of the selection instance of an emergency vehicle for an intervention
* `OSRM estimate from last observed GPS position`(json object): service route response from last observed GPS position of an OSRM instance (http://project-osrm.org/docs/v5.15.2/api/#route-service) setup with the Ile-de-France OpenStreetMap data
* `OSRM estimated distance from last observed GPS position`(float): distance (in meters) calculated by the OSRM route service from last observed GPS position
* `OSRM estimated distance from last observed GPS position`(float): distance (in meters) calculated by the OSRM route service from last observed GPS position
* `OSRM estimated duration from last observed GPS position`(float): transit delay (in seconds) calculated by the OSRM route service from last observed GPS position
* `time elapsed between selection and last observed GPS position` (float): in seconds
* `updated OSRM estimated duration` (float): time elapsed (in seconds) between selection and last observed GPS position + OSRM estimated duration from last observed GPS position


Good reading ! 


## 1.1 Load libraries 

```{r}
library(magrittr)
library(data.table)
library(sandwich)
library(dplyr)
library(stringr)
library(ggplot2)
library(DataExplorer)
```

## 1.2 Load data, transform them into Datatable for better computation time and combine them. 
```{r}
x_train <- read.csv("x_train.csv") %>% setDT
y_train <- read.csv("y_train.csv") %>% setDT
x_test <- read.csv("x_test.csv") %>% setDT
#View(x_train)
data <- cbind(x_train,y_train[,-1])#we don't keep id vehicule selection for no duplicate
```


## 1.3 File structure and content
Let's have an overview of the data sets using the *introduce* and *head* tools. First the training data:

```{r}
plot_intro(data)
```

```{r}
glimpse(data)
```

```{r}
plot_intro(x_test)
```

```{r}
glimpse(x_test)
```

We find : 
- we have a great mix of qualitative data and quantitative data
- some quali data are characters such as "status.preceding.selection, other dummy variables coded 0,1 such as $intervention.on.public.roads
- we have NA values
- We have ID variables that we can remove
- We will have to deal with outliers
- Mean of 
** `delta selection-departure`(int): elapsed time in seconds between the selection and the departure of the emergency vehicle
* **[TO PREDICT]** `delta departure-presentation`(int): elapsed time in seconds between the departure of the emergency vehicle and its presentation on the intervention scene
* **[TO PREDICT]** `delta selection-presentation `(int): elapsed time in seconds between the selection of the emergency vehicle and its presentation on the intervention scene (delta selection-departure + delta departure-presentation)


## 1.4 Missing values

```{r}
# visualize missing data
introduce(data)
plot_missing(data)
```

```{r}
introduce(x_train)
plot_missing(x_train)

```


We delete the useless column and the raw with empty cells
```{r}
data <- data[,-24] # delete the column OSMR response json object
data <- data[,-21] #delete the column delta position gps
```

Same with x_test data
```{r}
x_test<-x_test[,-24]
x_test<-x_test[,-21]
```

Let's check how many na it remains
```{r}
sum(is.na(data))
sum(is.na(x_test))
```
Good proporition (around 5% of dataset), acceptable to omit those values. 

```{r}
data <- na.omit(data)

which(is.na(data))
x_test<-na.omit(x_test)
```

(We apply same cleaning in x_train and y_train in case)
```{r}
y_train <- na.omit(y_train)
x_train<-na.omit(x_train)
```
Attention : combine en fonction de 'id intervention


## 1.5 Convertion into right format


Convert qualitative variables into factor
```{r}
data$alert.reason.category<- as.factor(data$alert.reason.category)
data$alert.reason<-as.factor(data$alert.reason)
data$location.of.the.event <- as.factor(data$location.of.the.event)
data$intervention.on.public.roads <- as.factor(data$intervention.on.public.roads)
data$emergency.vehicle.type <- as.factor(data$emergency.vehicle.type)
data$rescue.center <- as.factor(data$rescue.center)
data$status.preceding.selection  <- as.factor(data$status.preceding.selection)
data$departed.from.its.rescue.center  <- as.factor(data$departed.from.its.rescue.center)
data$floor<-as.factor(data$floor)
data$emergency.vehicle<-as.factor(data$emergency.vehicle)

```

Apply same in x_test
```{r}
x_test$alert.reason.category<- as.factor(x_test$alert.reason.category)
x_test$alert.reason<-as.factor(x_test$alert.reason)
x_test$location.of.the.event <- as.factor(x_test$location.of.the.event)
x_test$intervention.on.public.roads <- as.factor(x_test$intervention.on.public.roads )
x_test$emergency.vehicle.type <- as.factor(x_test$emergency.vehicle.type)
x_test$rescue.center <- as.factor(x_test$rescue.center)
x_test$status.preceding.selection  <- as.factor(x_test$status.preceding.selection)
x_test$departed.from.its.rescue.center  <- as.factor(x_test$departed.from.its.rescue.center)
x_test$floor<-as.factor(x_test$floor)
x_test$emergency.vehicle<-as.factor(x_test$emergency.vehicle)

```


Manage *Selection time 

 * `selection time` (datetime): selection time of the emergency vehicle
            * `date key selection` (int): selection date in YYYYMMDD format
            * `time key selection` (int): selection time in HHMMSS format


We can deleat selection time. We keep numeric format for date key selection and time key selection for now (more manageable for cor analysis and regression). 
For EDA part, we could convert them into date and time format


```{r}
data<-data[,-c("selection.time")]
```

Store quali, quali and quali with Ys variables 
```{r}
str(data)

data.quali<-data[,c(3,4,5,6,7,11,12,15,17)]

data.quanti.y<-data[,-c(3,4,5,6,7,11,12,15,17)] #with Ys

data.quanti<-data[,-c(3,4,5,6,7,11,12,15,17,24,25,26)]
```


# 2. EDA

## 2.1 Intro : map 
We start with a map of Paris and overlay a managable number of coordinates to get a general overview of the locations and distances in question. For this visualisation we use the [leaflet](https://rstudio.github.io/leaflet/) package, which includes a variety of cool tools for interactive maps. In this map you can zoom and pan through the interventation locations:

```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 1", out.width="100%"}
set.seed(1234)
foo <- sample_n(data, 8e3)

leaflet(data = foo) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircleMarkers(~ longitude.intervention, ~latitude.intervention, radius = 1,
                   color = "blue", fillOpacity = 0.3)

```

Comment maps : 

## 2.2 Dependant Variables Ys
We have 2 dependant variables and 1 global variable

```{r}
summary(y_train[,-1])
```

Extreme values for your Ys variables around 6 hours ! 

Plot density distribution for time of vehicle selection
```{r}

data %>%
  ggplot(aes(delta.selection.departure)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```

Note the logarithmic x-axis and square-root y-axis.

We find:

    the majority of vehicule rather timinh follow a rather smooth distribution that looks almost log-normal with a peak just short of 200 seconds, i.e. about 4 minutes.

    There are several suspiciously short rides with less than 10 seconds duration.

    Additionally, there is a strange delta-shaped peak of trip_duration just before the 1e5 seconds mark and even a few way above it:
    
Plot density distribution the time to present to the place
```{r}
data %>%
  ggplot(aes(delta.departure.presentation)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```

We find:

    same smooth distribution that looks almost log-normal with a peak around 400, 500 seconds, i.e. about 6 minutes.

From previous observation. 

Global variable : selection to arrival
around 8 to 10 mintues. 



In many fire departments the measurement of turnout time and travel time are done manually. An officer presses a button located in the vehicle to signal his departure and his arrival. This process introduces irregularities and variation in the data, which will need to be cleaned. 



Box plots Ys 

For delta.selection.departure
```{r}
data %>% 
  ggplot(aes(delta.selection.departure)) +
  geom_boxplot() 
```


```{r}
data %>% 
  ggplot(aes(delta.departure.presentation)) +
  geom_boxplot() 
```


Cor between Ys

```{r}
library(Hmisc)
library(corrplot)
corr<-rcorr(as.matrix(y_train[,-c(1,4)])) # We remove global and ID which will be cor
y_train_cor= corr$r

corr
corrplot(y_train_cor, method="square",type="upper", order="hclust", tl.col="black", tl.srt=45)
```

The 2 Ys are not corr between them


### 2.2.1 Manage outliers for Ys values

Plot 
  delta.selection.departure
```{r}
y_train %>% 
  mutate(
      delta.selection.departure_minutes = round(delta.selection.departure / 60, 0),
    duration_grp = case_when(
      between(delta.selection.departure_minutes, 0,  2)  ~ "Less than 2 minutes",
      between(delta.selection.departure_minutes, 2, 4) ~ "2 to 4 minutes",
      between(delta.selection.departure_minutes, 4, 8) ~ "8 to 12 minutes",
      delta.selection.departure_minutes >= 8 ~ "8 or more minutes"
    ),
    duration_grp = factor(duration_grp, 
                          levels = c("Less than 2 minutes", "2 to 4 minutes", "8 to 12 minutes", "12 or more minutes"))
  ) %>%
  group_by(duration_grp) %>% 
  ggplot(aes(x=duration_grp,group=duration_grp)) + 
  geom_bar(fill="#E41A1C") +
  labs(x="Group", y="count") +
  theme_minimal()
```
Most of data is around 0 to 12 max minutes for 


Departure to presentation
```{r}
y_train %>% 
  mutate(
      delta.departure.presentation_minutes = round(delta.departure.presentation / 60, 0),
    duration2_grp = case_when(
      between(delta.departure.presentation_minutes, 0,  5)  ~ "Less than 5 minutes",
      between(delta.departure.presentation_minutes, 5, 10) ~ "5 to 10 minutes",
      between(delta.departure.presentation_minutes, 10, 15) ~ "10 to 15 minutes",
      between(delta.departure.presentation_minutes, 15, 20) ~ "15 to 20 minutes",
      delta.departure.presentation_minutes >= 20 ~ " 20 or more minutes"
    ),
    duration2_grp = factor(duration2_grp, 
                          levels = c("Less than 5 minutes", "5 to 10 minutes", "10 to 15 minutes", "15 to 20 minutes","20 or more minutes" ))
  ) %>%
  group_by(duration2_grp) %>% 
  ggplot(aes(x=duration2_grp,group=duration2_grp)) + 
  geom_bar(fill="#E41A1C") +
  labs(x="Group", y="count") +
  theme_minimal()
```

Max 20 min

```{r}
y_train %>% 
  mutate(
      delta.selection.presentation_minutes = round(delta.selection.presentation / 60, 0),
    duration3_grp = case_when(
      between(delta.selection.presentation_minutes, 0,  5)  ~ "Less than 5 minutes",
      between(delta.selection.presentation_minutes, 5, 10) ~ "5 to 10 minutes",
      between(delta.selection.presentation_minutes, 10, 15) ~ "10 to 15 minutes",
      between(delta.selection.presentation_minutes, 15, 20) ~ "15 to 20 minutes",
      delta.selection.presentation_minutes >= 20 ~ " 20 or more minutes"
    ),
    duration3_grp = factor(duration3_grp, 
                          levels = c("Less than 5 minutes", "5 to 10 minutes", "10 to 15 minutes", "15 to 20 minutes","20 or more minutes" ))
  ) %>%
  group_by(duration3_grp) %>% 
  ggplot(aes(x=duration3_grp,group=duration3_grp)) + 
  geom_bar(fill="#E41A1C") +
  labs(x="Group", y="count") +
  theme_minimal()
```


=> Most of duration are between 0 to 20 min (1200 sec)
We can set our outlier cleaning


```{r}
data<- data[data$delta.selection.departure < 1200,]
data<-data[data$delta.departure.presentation < 1200,]
data<-data[data$delta.selection.presentation < 1200,]
```




### 2.2.2 Relation anaylis between Y and other variables
In this part, we will first try to check if there is relation between our dependant variables and the depedant

Let's study  Y0 'selection-departure', Y1'departure-presentation',Y2'selection-presentation' vs feature vars

data and y without GPS data

```{r}
data.nogps<-data[,-c(21,20)]
```


We sample data in 3000 observations for scatter plot

```{r}
set.seed(1234)
foocor.all <- sample_n(data.nogps, 3000)
```

Let's use here scatter plot. Scatter plot are plotted along two axes, the pattern of the resulting points revealing any correlation present. One pattern of special interest is a linear pattern, where the data has a general look of a line going uphill or downhill. L


For instance, let's plot y0 vs alert.reason.category

```{r}
car::scatterplot(delta.selection.departure ~ OSRM.estimated.duration, data = foocor.all, 
                 smoother = TRUE, grid = TRUE)
```
Here no clear linear correlation. Some slicly smooth trend. 
But let's take delta. departure. presentation vs the OSRM estiamted duration. 


```{r}
car::scatterplot(delta.departure.presentation~ OSRM.estimated.duration, data = foocor.all, 
                 smoother = TRUE, grid = TRUE)
```
We can observe a clear linear positive correlation. Normal since distance and time of presentation are correlated. 



Let's scattter plot matrix.  We just check the lines for ys vs other variables for now and try to identify visualy if there is some high explicative variable. 

Plot 5 first
```{r}
pairs(delta.selection.departure~.,data=foocor.all[,c(1,2,3,4,5,22,23,24)],
   main="Simple Scatterplot Matrix",lower.panel = NULL)

```

We find : 

It seems that we dont have clear linear cor. 


5 next
```{r}
pairs(delta.selection.departure~.,data=foocor.all[,c(6,7,8,9,10,11,22,23,24)],
   main="Simple Scatterplot Matrix",lower.panel = NULL)

```

5 next

```{r}
pairs(delta.selection.departure~.,data=foocor.all[,c(12,13,14,15,16,17,22)],
   main="Simple Scatterplot Matrix",lower.panel = NULL)

```

5 next
```{r}
pairs(delta.selection.departure~.,data=foocor.all[,c(12,13,14,15,16,17,22,23,24)],
   main="Simple Scatterplot Matrix",lower.panel = NULL)

```

5 next
```{r}
pairs(delta.selection.departure~.,data=foocor.all[,c(18,19,20,21,22,23,24)],
   main="Simple Scatterplot Matrix",lower.panel = NULL)

```


We find : 
clear linear cor. 

We will deeper our correlation analysis in next part. 





## 3. Explanatory data : Manage Outliers


### 3.1 Verify data outliers

#### 3.1.1 Quantitative Variables

##### 3.1.1.1 Histograms
```{r}

which(is.na(data.quanti)) #check for NA values before starting
#str(data.quanti)
#str(data.quali)
```

```{r}
hist(data.quanti$longitude.intervention, col="blue",main="Longitude intervention")
```

```{r}
hist(data.quanti$latitude.intervention, col="blue",main="Latitude intervention")
```

```{r}
hist(data.quanti$delta.status.preceding.selection.selection, col="blue",main="delta status preceding selection-selection")
```

```{r}
hist(data.quanti$longitude.before.departure, col="blue",main="longitude before departure ")
```

```{r}
hist(data.quanti$latitude.before.departure, col="blue",main="Latitude before departure ")
```

```{r}
hist(data.quanti$OSRM.estimated.distance, col="blue",main="OSRM estimated distance")
```

```{r}
hist(data.quanti$OSRM.estimated.duration, col="blue",main="OSRM estimated duration")
```

##### 3.1.1.2 Plot Variables Density Distribution 

```{r}
data.quanti %>%
  ggplot(aes(longitude.intervention)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```


```{r}
data.quanti %>%
  ggplot(aes(latitude.intervention)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```


```{r}
data.quanti %>%
  ggplot(aes(delta.status.preceding.selection.selection)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```


```{r}
data.quanti %>%
  ggplot(aes(longitude.before.departure)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```


```{r}
data.quanti %>%
  ggplot(aes(latitude.before.departure)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```


```{r}
data.quanti %>%
  ggplot(aes(OSRM.estimated.distance)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```


```{r}
data.quanti %>%
  ggplot(aes(OSRM.estimated.duration)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```

##### 3.1.1.3 Boxplots

```{r}
boxplot(data.quanti$longitude.intervention, col="blue",main="Longitude intervention")
```

```{r}
boxplot(data.quanti$latitude.intervention, col="blue",main="Latitude intervention")
```

```{r}
boxplot(data.quanti$delta.status.preceding.selection.selection , col="blue",main="delta status preceding selection-selection")
```

```{r}
boxplot(data.quanti$longitude.before.departure, col="blue",main="longitude before departure")
```

```{r}
boxplot(data.quanti$latitude.before.departure, col="blue",main="latitude before departure")
```

```{r}
boxplot(data.quanti$OSRM.estimated.distance, col="blue",main="OSRM estimated distance")
```

```{r}
boxplot(data.quanti$OSRM.estimated.duration, col="blue",main="OSRM estimated duration")
```

##### 3.1.1.3 Manage Outliers 

```{r}
data.clean <- data[data$delta.status.preceding.selection.selection < 100000,]
data.clean <- data[data$OSRM.estimated.duration < 1000,]

#str(data.clean)

#Assign the new value to data.quanti
data.quanti<-data.clean[,-c(3,4,5,6,7,11,12,15,17,24,25,26)]

```

#### 3.1.2 Qualitative Variables

##### 3.1.2.1 Tables 

```{r}
str(data.quali)
```
```{r}
table(data.quali$alert.reason.category)
prop.table(table(data.quali$alert.reason.category))
```

```{r}
table(data.quali$alert.reason) 
prop.table(table(data.quali$alert.reason))
```
Csq -> we need to combine several categories for alert reason variable

```{r}
table(data.quali$intervention.on.public.roads) 
prop.table(table(data.quali$intervention.on.public.roads))
```

```{r}
table(data.quali$floor) 
prop.table(table(data.quali$floor))
```
Csq -> we need to combine several categories for floors

```{r}
table(data.quali$location.of.the.event) 
prop.table(table(data.quali$location.of.the.event))
```
Csq -> we need to combine several categories for location of the event variable

```{r}
table(data.quali$emergency.vehicle.type)
prop.table(table(data.quali$emergency.vehicle.type))
```
csq -> we need to combine several categories for emergency vehicle type variable

```{r}
table(data.quali$rescue.center)
prop.table(table(data.quali$rescue.center))
```
csq -> we need to combine several categories for rescue center variable

```{r}
table(data.quali$status.preceding.selection)
prop.table(table(data.quali$status.preceding.selection))
```
csq -> we need to combine several categories for status preceding selection variable

```{r}
table(data.quali$departed.from.its.rescue.center)
prop.table(table(data.quali$departed.from.its.rescue.center))
```
csq -> we need to combine several categories for departed from its rescue center variable


##### 3.1.2.2 Barplots 

```{r}
barplot(table(data.quali$alert.reason.category),horiz = F,cex.names=0.8,col="blue",main="Alert Reason Category",ylab="Frequency", plot=TRUE)
```

```{r}
barplot(table(data.quali$alert.reason),horiz = F,cex.names=0.8,col="blue",main="Alert Reason Category",ylab="Frequency", plot=TRUE)
```
Csq -> we need to combine several categories for alert reason variable

```{r}
barplot(table(data.quali$intervention.on.public.roads),horiz = F,cex.names=0.8,col="blue",main="Intervention on public road",ylab="Frequency", plot=TRUE)
```

```{r}
barplot(table(data.quali$floor),horiz = F,cex.names=0.8,col="blue",main="Floors",ylab="Frequency", plot=TRUE)
```
Csq -> we need to combine several categories for floors

```{r}
barplot(table(data.quali$location.of.the.event),horiz = F,cex.names=0.8,col="blue",main="Location of the event",ylab="Frequency", plot=TRUE)
```
Csq -> we need to combine several categories for location of the event variable

```{r}
barplot(table(data.quali$emergency.vehicle.type),horiz = F,cex.names=0.8,col="blue",main="Emergency Vehicle Type",ylab="Frequency", plot=TRUE)
```
csq -> we need to combine several categories for emergency vehicle type variable

```{r}
barplot(table(data.quali$rescue.center),horiz = F,cex.names=0.8,col="blue",main="Rescue center variable",ylab="Frequency", plot=TRUE)
```
csq -> we need to combine several categories for rescue center variable

```{r}
barplot(table(data.quali$status.preceding.selection),horiz = F,cex.names=0.8,col="blue",main="Emergency Vehicle Type",ylab="Frequency", plot=TRUE)
```

```{r}
barplot(table(data.quali$departed.from.its.rescue.center),horiz = F,cex.names=0.8,col="blue",main="Departed from its rescue center",ylab="Frequency", plot=TRUE)
```
csq -> we need to combine several categories for departed from its rescue center variable


##### 3.1.2.3 Group Together Categories With Low Frequency & Manage Outliers

for the floor variable, group everything below -2 & everything after 10
```{r}

data.clean <- data[data$delta.status.preceding.selection.selection < 100000,]
data.clean <- data[data$OSRM.estimated.duration < 1000,]

table(data.clean$floor)

levels(data.clean$floor) <- list("-2"=c("-10","-9","-6","-5","-4","-3", "-2"),
                                 "-1"=c("-1"), "0"=c("0"), "1"=c("1"), "2"=c("2"), "3"=c("3"),
                                  "4"=c("4"), "5"=c("5"), "6"=c("6"), "7"=c("7"), "8"=c("8"), "9"=c("9"), "10"=c("10"),
                                  "11"=c("11"), "12"=c("12"), "13"=c("13"), "14"=c("14"), "15"=c("15"), "16"=c("16"),
                                 "17"=c("17","18","19","20","21","22", "23", 
                                        "24","25","26","27","28","29", "30", "31", "32", "33", "37", "52", "79", "100"))

table(data.clean$floor)

barplot(table(data.clean$floor),horiz = F,cex.names=0.8,col="blue",main="Floors",ylab="Frequency", plot=TRUE)

data.quali<-data.clean[,c(3,4,5,6,7,11,12,15,17)]
```

#### 3.1.2 How top influencer predictors and speed correlate ? 

```{r}
data.clean %>%
  ggplot(aes(x=alert.reason, y=OSRM.estimated.distance)) +
  geom_boxplot()
```


```{r}
data.clean %>%
  ggplot(aes(x=rescue.center, y=OSRM.estimated.distance)) +
  geom_boxplot()
```


```{r}
data.clean %>%
  ggplot(aes(x=alert.reason.category, y=OSRM.estimated.distance)) +
  geom_boxplot()
```

### GPS data [if time]

We have to do some feature enreginering with this data. 
But if we have distance OSRM, is it not sufficiant ? 


First GPS.track.departure.presentation is stored as a set of character lat and log. 

* `GPS tracks departure-presentation` (float pair list): successive GPS positions (*longitude,latitude;longitude,latitude,* etc.) of the vehicle between departure and presentation. This information is for informational purposes to study vehicle behaviors. (The beacons, emitting the GPS positions of vehicles, are currently not always lit)


```{r}
data$GPS.tracks.departure.presentation %>% head
```
Let's convert it into 2 columns : 
GPS.track.departure.presentation.lat
GPS.track.departure.presentation.long



```{r}
str_extract_all(data$GPS.tracks.departure.presentation, "[,]+", simplify=TRUE)

GPS.track.departure.presentation.lat<-(str_extract_all(data$GPS.tracks.departure.presentation, "[^,]+"))

GPS.track.departure.presentation.lat %>% head

GPS.track.departure.presentation.long<-as.data.frame(str_extract_all(data$GPS.tracks.departure.presentation, "[,^]+"))

```

```{r}
# Get the parenthesis and what is inside
GPS.track.departure.presentation.lat <-(str_extract_all(data$GPS.tracks.departure.presentation, "[^,]+", simplify = TRUE))
```

```{r}
GPS.track.departure.presentation.lat %>% head
```


```{r}
GPS.tracks.departure.presentation.lat %>% head
```


# We transform variables [if time]
```{r}
# transform variables
data.clean$log.longitude.intervention <- log(data.clean$longitude.intervention)
data.clean$log.latitude.intervention<- log(data.clean$latitude.intervention)
data.clean$log.delta.status.preceding.selection.selection <- log(data.clean$delta.status.preceding.selection.selection)
data.clean$log.delta.position.gps.previous.departure.departure <- log(data.clean$delta.position.gps.previous.departure.departure) 
data.clean$log.longitude.before.departure <- log(data.clean$longitude.before.departure)
data.clean$log.latitude.before.departure <- log(data.clean$latitude.before.departure)
data.clean$log.OSRM.estimated.distance <- log(data.clean$OSRM.estimated.distance)
data.clean$log.OSRM.estimated.duration   <- log(data.clean$OSRM.estimated.duration)
```

```{r}
# Histograms
hist(data.clean$log.longitude.intervention, col="blue",main="Log longitude intervention")
hist(data.clean$log.latitude.intervention, col="blue",main=" Log Latitutde intervention")
hist(data.clean$log.delta.status.preceding.selection.selection , col="blue",main=" Log delta status preceding selection-selection")
hist(data.clean$log.delta.position.gps.previous.departure.departure, col="blue",main="Log delta position gps previous departure-departure (int)")
hist(data.clean$log.longitude.before.departure, col="blue",main="Log longitude before departure ")
hist(data.clean$log.latitude.before.departure, col="blue",main="Log Latitude before departure ")
hist(data.clean$log.OSRM.estimated.distance, col="blue",main="Log OSRM estimated distance")
hist(data.clean$log.OSRM.estimated.duration, col="blue",main="Log OSRM estimated duration")
```

```{r}
# Boxplot
boxplot(data.clean$log.longitude.intervention, col="blue",main="Log longitude intervention")
boxplot(data.clean$log.latitude.intervention, col="blue",main=" Log Latitutde intervention")
boxplot(data.clean$log.delta.status.preceding.selection.selection , col="blue",main=" Log delta status preceding selection-selection")
boxplot(data.clean$log.delta.position.gps.previous.departure.departure, col="blue",main="Log delta position gps previous departure-departure (int)")
boxplot(data.clean$log.longitude.before.departure, col="blue",main="Log longitude before departure ")
boxplot(data.clean$log.latitude.before.departure, col="blue",main="Log Latitude before departure ")
boxplot(data.clean$log.OSRM.estimated.distance, col="blue",main="Log OSRM estimated distance")
boxplot(data.clean$log.OSRM.estimated.duration, col="blue",main="Log OSRM estimated duration")
summary(data.clean)
```

```{r}
# Normality study
# QQ Plot
# when the variable is normally distributed
# points are aligned on the first bisector

qqnorm(data.clean$floor, main="Normality floor")
qqline(data.clean$floor)

qqnorm(data.clean$longitude.intervention, main="Normality longitude intervention")
qqline(data.clean$longitude.intervention)
qqnorm(data.clean$log.longitude.intervention, main="Normality log longitude intervention")
qqline(data.clean$log.longitude.intervention)

qqnorm(data.clean$latitude.intervention, main="Normality latitude intervention")
qqline(data.clean$latitude.intervention)
qqnorm(data.clean$log.latitude.intervention, main="Normality log latitude intervention")
qqline(data.clean$log.latitude.intervention)

qqnorm(data.clean$delta.status.preceding.selection.selection, main="Normality delta status preceding selection-selection")
qqline(data.clean$delta.status.preceding.selection.selection)
#qqnorm(data.clean$log.delta.status.preceding.selection.selection, main="Normality log delta status preceding selection-selectio")
#not possible

qqnorm(data.clean$delta.position.gps.previous.departure.departure, main="Normality delta status preceding selection-selection")
qqline(data.clean$delta.position.gps.previous.departure.departure)
#qqnorm(data.clean$log.delta.position.gps.previous.departure.departure, main="Normality log delta status preceding selection-selection")
#not possible

qqnorm(data.clean$longitude.before.departure, main="Normality longitude before departure")
qqline(data.clean$longitude.before.departure)
qqnorm(data.clean$log.longitude.before.departure, main="Normality log longitude before departure")
qqline(data.clean$log.longitude.before.departure)

qqnorm(data.clean$latitude.before.departure, main="Normality latitude before departure")
qqline(data.clean$latitude.before.departure)
qqnorm(data.clean$log.latitude.before.departure, main="Normality log latitude before departure")
qqline(data.clean$log.latitude.before.departure)

qqnorm(data.clean$OSRM.estimated.distance, main="NormalityOSRM estimated distance")
qqline(data.clean$OSRM.estimated.distance)
qqnorm(data.clean$log.OSRM.estimated.distance, main="Normality log OSRM estimated distance")
qqline(data.clean$log.OSRM.estimated.distance)

qqnorm(data.clean$OSRM.estimated.duration, main="Normality OSRM estimated duration")
qqline(data.clean$OSRM.estimated.duration)
qqnorm(data.clean$log.OSRM.estimated.duration, main="Normality log OSRM estimated duration")
qqline(data.clean$log.OSRM.estimated.duration)
```

## 4. correlation
### Correlation analysis

```{r warning=FALSE, collapse=TRUE}
corr<-rcorr(as.matrix(dataset))
dataset_coeff = corr$r

corrplot(dataset_coeff, method="square",type="upper", order="hclust", tl.col="black", tl.srt=45)
```

```{r warning=FALSE, collapse=TRUE}
sort(dataset_coeff[,31],decreasing= TRUE )
```
We use the first graph and the attached table to identify the variables most correlated with the target. 

Although we can notice that some features are highly correlated with each other (>0.5), we choose to keep them for more precision in our model.    
   
We observe that the variables **HTTPS** and **AnchorULR** are most the correlated to the target.   
Let us plot distribution of Class for the most correlated features to the the target (HTTPS, AnchorURL,PrefixSuffix). 

***

```{r}
str(data.quanti)

data.quanti.nogps <- data.quanti[,c(-11, -12)] #delete gps columns

str(data.quanti.nogps)

cor(data.quanti.nogps)
```
We analyse the variables greater than 0.95 and we keep the one which is the more correlated to Y

1.
Longitude.intervention  and longitude.before.departure are very correlated 0,98 > 0,95
We keep Longitutde intervention and Y 0,057
We don't keep longitude.before.departure 

2.
Latitude.intervention and latitude.before.departure are very correlated 0,98 > 0,95
We don't keep latitude.intervention and Y  0.016
We keep latitude.before.departure

```{r}
str(data.clean)

data.variables.without.cor <- data.clean[,-c(18,19)]
str(data.variables.without.cor)

```
  



##### PCA

```{r}
data.variables.PCA <- data.quanti[,-c(11,12)]
data.variables.PCA <- scale(data.variables.PCA, center = TRUE)
```
For the PCA, we analayse our quantify variables and we remove the GPS variables that aren't numerical
We center the data

```{r}
res.pca=PCA(data.variables.PCA, scale.unit=TRUE, ncp=11, graph=F)
summary(res.pca)
```
We can stop at Dimension 7 because we have reached a cumulative variance of 99%

```{r}
round(res.pca$eig,7)
```
The first 2 axes account for 40% of the total inertia. 
```{r}
inertia=res.pca$eig[,2]
barplot(inertia,ylab="% Unertia",names.arg=round(inertia,7))+
title("eigenvalues (inertias or variances of each component) in %")
```

```{r}
res.pca=PCA(data.variables.PCA, scale.unit=TRUE, ncp=7, graph=F)
graph.var (res.pca, new.plot=TRUE)
```

```{r}
graph.var (res.pca, lim.cos2.var=0.5, new.plot=TRUE)
```



 
#Qualitatives variables 
```{r}
tapply(data.clean$delta.departure.presentation, data.clean$alert.reason.category, summary)
bartlett.test(data.clean$delta.departure.presentation, data.clean$alert.reason.category)
bartlett.test(data.clean$delta.departure.presentation, data.clean$intervention.on.public.roads) #pvalue <0,05
bartlett.test(data.clean$delta.departure.presentation, data.clean$status.preceding.selection) #pvalue <0,05
bartlett.test(data.clean$delta.departure.presentation, data.clean$departed.from.its.rescue.center)#pvalue <0,05
bartlett.test(data.clean$delta.departure.presentation, data.clean$month)#pvalue <0,05

data.clean$departed.from.its.rescue.center
```

```{r}
data.variables.without.cor <- na.omit(data.variables.without.cor)
```

#Etude de correlation, PCA pour réduire facteur et variable. 

#Regrouper véhicule, ressources center, location of the event

# OLS - Regression

Split data: train et test
On predict sur le test du train. 
Faire comparaison de mod?le. 


On garde x_test pour le final predict

```{r}
#Linear Regression,
str(data.variables.without.cor)

options(max.print = 10000)

lm <- lm(delta.selection.presentation ~ 
           alert.reason.category
         + intervention.on.public.roads
         + floor
         + location.of.the.event
         + longitude.intervention
         + latitude.intervention
         + emergency.vehicle.type
         + rescue.center
         + status.preceding.selection
         + delta.status.preceding.selection.selection
         + departed.from.its.rescue.center
         + OSRM.estimated.distance
         + OSRM.estimated.duration
           ,data = data.variables.without.cor)

summary(lm)


```
# We can remove the rescue center because he has the higher pvalue
```{r}
lm1 <- lm(delta.selection.presentation ~ 
           alert.reason.category
         + intervention.on.public.roads
         + floor
         + location.of.the.event
         + longitude.intervention
         + latitude.intervention
         + emergency.vehicle.type
         + status.preceding.selection
         + delta.status.preceding.selection.selection
         + departed.from.its.rescue.center
         + OSRM.estimated.distance
         + OSRM.estimated.duration
           ,data = data.variables.without.cor)

summary(lm1)
```

# We  remove the departed.from.its.rescue.center because he has the higher pvalue
```{r}
lm2 <- lm(delta.selection.presentation ~ 
           alert.reason.category
         + intervention.on.public.roads
         + floor
         + location.of.the.event
         + longitude.intervention
         + latitude.intervention
         + emergency.vehicle.type
         + status.preceding.selection
         + delta.status.preceding.selection.selection
         + OSRM.estimated.distance
         + OSRM.estimated.duration
           ,data = data.variables.without.cor)

summary(lm2)
```

# Multicolinéarity 

```{r}
library(car)

vif(lm2)

#cor(data.quanti.without.cor)

lm3 <- lm(delta.selection.presentation ~ 
           alert.reason.category
         + intervention.on.public.roads
         + floor
         + location.of.the.event
         + longitude.intervention
         + latitude.intervention
         + emergency.vehicle.type
         + status.preceding.selection
         + delta.status.preceding.selection.selection
         + OSRM.estimated.distance
           ,data = data.variables.without.cor)

summary(lm3)

vif(lm3)
#variables qualitatives 

```
# Residuals analysis

Study the residuals of the selected model
What we've done is not enough to validate the model. We need to study the residuals
if hypothesis are not validated (see course.), the test of the coefficient are false 
Study the residuals of the selected model

## Is residuals means 0?

```{r}
#mean of residuals
summary(lm3$residuals) 
```
Yes it is !

## Are residuals normally distributed?

Normality test : shapiro test
H0 : Normality and H1 : no normality
```{r}

shapiro.test(lm3$residuals)

#Error in shapiro.test(regmult3$residuals) : la taille de l'échantillon doit être comprise entre 3 et 5000

library(tseries)

jarque.bera.test(lm3$residuals)

#install.packages("nortest")
library(nortest)
ad.test(lm3$residuals)


```



No normality because p-value is << 5%. Here, residuals are not normally distributed. 
NB : non normality could appear because of outliers. This is not the case here. 



```{r}

qqnorm(lm3$residuals)
qqline(lm3$residuals)
```

## Are residuals homoskedastic?

1. First model which is not considering heteroskedasticity

```{r}

plot(lm3$residuals~lm3$fitted)

library(lmtest)

# Breush Pagan test H0 : homoskedasticity against H1 : heteroskedasticity 

bptest(lm3)

```
pvalue << 5%, we reject H0
residuals are heteroskedastic

In case of heteroskedasticity, we have to use a robust standard error estimator. Otherwise, all our t-tests will be wrong.


2. Second model taking into account heteroskedasticity

```{r}

library(sandwich)

#Calculate the robust covariance matrix

vcov2 <- vcovHC(lm3, type = "HC1")

coeftest(lm3, vcov. = vcov2)

#The estimated value of the coefficients remains
#the same but the value of the t-test changes.
#A coefficient could be significant in the first
#model and no more in the second
```

# Are the residuals correlated ?

There are several tests for autocorrelation
Durbin-Watson test is one of the most often used

H0 : Residuals are non autocorrelated
H1 : Residuals are autocorrelated

1. First model which is not considering heteroskedasticity

```{r}

library(car)

# Durbin Watson test where H0 : residuals are not autocorrelated against H1 : residuals are aucorrelated
durbinWatsonTest (lm3,max.lag=1)

# doesn't work....
```

2. Second model taking into account heteroskedasticity

```{r}

library(sandwich)

#Calculate the robust covariance matrix

vcov4 <- NeweyWest(lm3)

coeftest(lm3, vcov. = vcov2)

#The estimated value of the coefficients remains
#the same but the value of the t-test changes.
#A coefficient could be significant in the first
#model and no more in the second
```


Just for test 
```{r}
lm.selection.departure <- lm(data.clean$delta.selection.departure~., data=data.clean[,-12])

summary(lm.selection.departure)

lm1.selection.departure<-(data.clean$delta.selection.departure ~data.clean$delta.status.preceding.selection.selection+factor(data.clean$intervention.on.public.roads), data=data.clean)
summary(lm1.selection.departure)

```


```{r}
library(tree)
tree1.train <-  tree(delta.selection.departure~.,data=data.clean[,-c(7,1,11,12)])
summary(tree1.train)
plot(tree1.train)
text(tree1.train,pretty = 0)

tree1.predict<-predict(tree1.train, newdata=x_test)

```

