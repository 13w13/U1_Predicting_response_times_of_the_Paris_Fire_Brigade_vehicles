---
title: "Predicting response times of the Paris Fire Brigade vehicles"
author: "Edgar Jullien, Antoine Settelen, Simon Weiss"
date: '`r Sys.Date()`'

output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

## Presentation of the project

This group project responds to **professor Nadine Galy instructions** written below :  
The project involves identifying a real-world business problem or opportunity and designing and implementing an analysis plan to address it using at least one of the modelling methods studied in the course. You are free to choose any business problem or opportunity or public policy issue that you consider challenging and useful to address using business analytics.
The data that you use should be readily available and verifiable.

This is a notebook for the [Paris Fire Brigate](https://paris-fire-brigade.github.io/data-challenge/challenge.html) data challenge 2020 with [ENS](https://challengedata.ens.fr/participants/challenges/21/) and [College de France](https://www.college-de-france.fr/site/stephane-mallat/Challenges-2020.htm).


**The goal of this playground challenge** is to predict the *The response times of the Paris Fire Brigade vehicles * which is the delay between:
* the selection of a rescue vehicle (the time when a rescue team is warned) 
* and the rescue team arrival time at the scene of the request (information sent manually via portable radio)

This measurement is composed by the 2 following periods of time: 
* the activation period of the rescue team 
* the transit time of the rescue team

Based on features like trip coordinates, pickup date, type of the arrivall destination, vehicules etc.. 

The [data](https://challengedata.ens.fr/participants/challenges/21/) which covers the entier year 2018 for which inoperable data have been squeezed out comes in the shape of 219 337 training observations and 108 033 test observation. The dataset covers the entire year of 2018. 
Each row contains one Paris fire brigade intervention.

"Response time is one of the most important factors for firefighters because their ability to save lives and rescue people depends on it. Every fire department in the world seeks strategies to decrease their response time, and several analyses have been conducted in the past years to determine what could impact response time. In the meantime, fire departments have been collecting data on their interventions; yet, few of them actually use data science to develop a data-driven decision making approach."https://medium.com/crim/predicting-the-response-times-of-firefighters-using-data-science-da79f6965f93


"A lot of fire departments and emergency services rely on geographic information systems tools, such as ESRI ARCGis or Network Analyst, to obtain estimations about the response time. These tools rely on computing the shortest route using a graphical representation of the road network, which usually gives an accurate estimate of the travel time. Their drawback is that they cannot always take into consideration external dynamic factors such as the weather, traffic or type of units or intervention. Hence, there is an opportunity for machine learning tools to be used here."



**In this notebook**, we will first study and visualize the original data, engineer new features, and examine potential outliers. Then, we implement a boosted Tree for our first model, do some dimension reductions on qualitative features and implement a linear regression. Finaly, we created a final predict and uploaded it to the data plateforme. 

We hope that this notebook will have good results to the challenge and responds fully to Nadine Galy requirement.
As always, any feedback, questions, or constructive criticism are much appreciated.


## Features description


**Input parameters (x_train.csv and x_test.csv):**

* **[ID]** `emergency vehicle selection`: identifier of the selection instance of an emergency vehicle for an intervention
* Intervention
    * `intervention`: identifier of the intervention
    * Alert reason
        * `alert reason category` (category): alert reason category
        * `alert reason` (category): alert reason
    * Address
        * `intervention on public roads` (boolean): 1 when it concerns an intervention on public roads, 0 otherwise
        * `floor` (int): floor of the intervention
        * `location of the event` (category): qualifies the location of the emergency request, for example: entrance hall, boiler room, motorway, etc.
        * `longitude intervention` (float): approximate longitude of the intervention address. **ATTENTION: `intervention_longitude`** !
        * `latitude intervention` (float): approximate latitude of the intervention address. **ATTENTION: `intervention_latitude`** !
    * Emergency vehicle
        * `emergency vehicle`: identifier of the emergency vehicle
            * `emergency vehicle type` (category): type of the emergency vehicle
            * `rescue center` (category): identifier of the rescue center to which belong the vehicle (parking spot of the emergency vehicle)
        * `selection time` (datetime): selection time of the emergency vehicle
            * `date key selection` (int): selection date in YYYYMMDD format
            * `time key selection` (int): selection time in HHMMSS format
        * State of the emergency vehicle preceding its selection for an intervention
            * Operational status of the vehicle preceding its selection
                * `status preceding selection` (category): status of the emergency vehicle prior to selection. An emergency vehicle is in various statuses during an intervention:
                    * **Selection** - selection of the emergency vehicle by the rescue commitment application
                    * **Departed** - the vehicle starts its route to the location of the emergency request
                    * **Presented** - the vehicle arrives at the location of the request
                    * **Hospital transportation** - the vehicle starts its transport of a victim to hospital
                    * **Hospital arrival** - the vehicle arrives at the hospital
                    * **Leaving hospital** - the vehicle leaves the hospital
                    * **Returned** - the vehicle has returned to its parking spot
                    * **Leave the premises** - because the vehicle can also simply leave the scene of an intervention without having to transport any victim
                    * **Not available** - for various reasons the vehicle can be in an unavailable position
                    * **Not relevant** - statutes without interest
                * `delta status preceding selection-selection` (int): number of seconds before the vehicle was selected when its previous status was entered
            * `departed from its rescue center` (boolean) : 1 when the vehicle departed from its rescue center (emergency vehicle parking spot), 0 otherwise
            * GPS position of the vehicle before departure
                * `longitude before departure` (float): longitude of the position of the vehicle preceding his departure. **ATTENTION: `departure_longitude`** !
                * `latitude previous departure` (float): latitude of the position of the vehicle preceding his departure. **ATTENTION: `departure_latitude`** !
                * `delta position gps previous departure-departure` (int): number of seconds before the selection of the vehicle where its GPS position was recorded (when not parked at its emergency center)
            * GPS tracks
                * `GPS tracks departure-presentation` (float pair list): successive GPS positions (*longitude,latitude;longitude,latitude,* etc.) of the vehicle between departure and presentation. This information is for informational purposes to study vehicle behaviors. (The beacons, emitting the GPS positions of vehicles, are currently not always lit)
                * `GPS tracks departure-presentation datetime` (datetime list): datetime associated with successive GPS positions between the departure and the presentation of the vehicle.
            * Estimated route
                * `OSRM estimated route` (json object): service route response of an OSRM instance (http://project-osrm.org/docs/v5.15.2/api/#route-service) setup with the Ile-de-France OpenStreetMap data
                * `OSRM estimated distance` (float): distance calculated by the OSRM route service
                * `OSRM estimated duration` (float): transit delay calculated by the OSRM route service

**Output parameters (y_train.csv and y_test.csv):**

* **[ID]** `emergency vehicle selection`: identifier of the selection instance of an emergency vehicle for an intervention
* **[TO PREDICT]** `delta selection-departure`(int): elapsed time in seconds between the selection and the departure of the emergency vehicle
* **[TO PREDICT]** `delta departure-presentation`(int): elapsed time in seconds between the departure of the emergency vehicle and its presentation on the intervention scene
* **[TO PREDICT]** `delta selection-presentation `(int): elapsed time in seconds between the selection of the emergency vehicle and its presentation on the intervention scene (delta selection-departure + delta departure-presentation)



**Supplementary files (x_train_additional_file.csv and x_test_additional_file.csv)**

* **[ID]** `emergency vehicle selection`: identifier of the selection instance of an emergency vehicle for an intervention
* `OSRM estimate from last observed GPS position`(json object): service route response from last observed GPS position of an OSRM instance (http://project-osrm.org/docs/v5.15.2/api/#route-service) setup with the Ile-de-France OpenStreetMap data
* `OSRM estimated distance from last observed GPS position`(float): distance (in meters) calculated by the OSRM route service from last observed GPS position
* `OSRM estimated distance from last observed GPS position`(float): distance (in meters) calculated by the OSRM route service from last observed GPS position
* `OSRM estimated duration from last observed GPS position`(float): transit delay (in seconds) calculated by the OSRM route service from last observed GPS position
* `time elapsed between selection and last observed GPS position` (float): in seconds
* `updated OSRM estimated duration` (float): time elapsed (in seconds) between selection and last observed GPS position + OSRM estimated duration from last observed GPS position


Good reading ! 


## 1.1 Load libraries 

```{r}
library(magrittr)
library(data.table)
library(sandwich)
library(dplyr)
library(ggplot2)
library(DataExplorer)
library(hms)
library(imputeTS)
library(leaflet)
library(Hmisc)
library(FactoMineR)
library(BCA)
library(corrplot)
library(Matrix)
library(caret)

```

## 1.2 Load data, transform them into Datatable for better computation time and combine them. 
```{r}
x_train <- read.csv("x_train.csv") %>% setDT
y_train <- read.csv("y_train.csv") %>% setDT
x_test <- read.csv("x_test.csv") %>% setDT
#View(x_train)
data <- cbind(x_train,y_train[,-1])#we don't keep id vehicule selection for no duplicate

#We rename a column which has a special caracter 
c<- colnames(data)
c[14] <- "date.key.selection"
c[15] <- "time.key.selection"
colnames(data) <- c

#Same for x_test
c<- colnames(x_test)
c[14] <- "date.key.selection"
c[15] <- "time.key.selection"
colnames(x_test) <- c
```


## 1.3 File structure and content
Let's have an overview of the data sets using the *introduce* and *head* tools. First the training data:

```{r}
plot_intro(data)
```

```{r}
glimpse(data)
```

```{r}
plot_intro(x_test)
```

```{r}
glimpse(x_test)
```

We find : 
- We have a great mix of qualitative data and quantitative data
- Some quali data are characters such as "status.preceding.selection, other dummy variables coded 0,1 such as $intervention.on.public.roads
- We have NA values
- We have ID variables that we can remove
- We will have to deal with outliers



## 1.4 Missing values

```{r}
# visualize missing data
introduce(data)
plot_missing(data)
```

```{r}
introduce(x_train)
plot_missing(x_train)

```


We remoev the useless column and the raw with empty cells
```{r}
data <- data[,-24] # delete the column OSMR response json object
data <- data[,-21] #delete the column delta position gps
```

Same with x_test data
```{r}
x_test<-x_test[,-24]
x_test<-x_test[,-21]
```

Let's check how many na it remains
```{r}
sum(is.na(data))
sum(is.na(x_test))
```
Good proporition (around 5% of dataset), acceptable to omit those values. 

```{r}
data <- na.omit(data)

which(is.na(data))
```

(We apply same cleaning in x_train and y_train in case)
```{r}
y_train <- na.omit(y_train)
x_train<-na.omit(x_train)
```


## 1.5 Convertion into right format


Convert qualitative variables into factor
```{r}
data$alert.reason.category<- as.factor(data$alert.reason.category)
data$alert.reason<-as.factor(data$alert.reason)
data$location.of.the.event <- as.factor(data$location.of.the.event)
data$intervention.on.public.roads <- as.factor(data$intervention.on.public.roads)
data$emergency.vehicle.type <- as.factor(data$emergency.vehicle.type)
data$rescue.center <- as.factor(data$rescue.center)
data$status.preceding.selection  <- as.factor(data$status.preceding.selection)
data$departed.from.its.rescue.center  <- as.factor(data$departed.from.its.rescue.center)
data$floor<-as.factor(data$floor)
data$emergency.vehicle<-as.factor(data$emergency.vehicle)
```



Apply same in x_test
```{r}
x_test$alert.reason.category<- as.factor(x_test$alert.reason.category)
x_test$alert.reason<-as.factor(x_test$alert.reason)
x_test$location.of.the.event <- as.factor(x_test$location.of.the.event)
x_test$intervention.on.public.roads <- as.factor(x_test$intervention.on.public.roads )
x_test$emergency.vehicle.type <- as.factor(x_test$emergency.vehicle.type)
x_test$rescue.center <- as.factor(x_test$rescue.center)
x_test$status.preceding.selection  <- as.factor(x_test$status.preceding.selection)
x_test$departed.from.its.rescue.center  <- as.factor(x_test$departed.from.its.rescue.center)
x_test$floor<-as.factor(x_test$floor)
x_test$emergency.vehicle<-as.factor(x_test$emergency.vehicle)

```


Manage *Selection time 

 * `selection time` (datetime): selection time of the emergency vehicle
            * `date key selection` (int): selection date in YYYYMMDD format
            * `time key selection` (int): selection time in HHMMSS format


We can delete selection time. We keep numeric format for date key selection and time key selection for now (more manageable for cor analysis and regression). 
For EDA part, we could convert them into date and time format


```{r}
data<-data[,-c("selection.time")]
x_test<-x_test[,-c("selection.time")]
```

Store quali, quali and quali with Ys variables 
```{r}
str(data)
colnames(data)
data.quali<-data[,c(3,4,5,6,7,10,11,12,15,17)]


data.quanti.y<-data[,-c(3,4,5,6,7,10,11,12,15,17)] #with Ys

data.quanti<-data[,-c(3,4,5,6,7,10,11,12,15,17,24,25,26)]
```


# 2. EDA

## 2.1 Intro : map 
We start with a map of Paris and overlay a manageable number of coordinates to get a general overview of the locations and distances in question. For this visualization we use the [leaflet](https://rstudio.github.io/leaflet/) package, which includes a variety of nice tools for interactive maps. In this map you can zoom and pan through the intervention locations:

```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 1", out.width="100%"}
set.seed(1234)
foo <- sample_n(data, 8e3)

leaflet(data = foo) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircleMarkers(~ longitude.intervention, ~latitude.intervention, radius = 1,
                   color = "blue", fillOpacity = 0.3)

```


## 2.2 Dependant Variables Ys
We have 2 dependant variables and 1 global variable

```{r}
summary(y_train[,-1])
```

Extreme values for your Ys variables around 6 hours ! 

Plot density distribution for time of vehicle selection
```{r}

data %>%
  ggplot(aes(delta.selection.departure)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```

Note the logarithmic x-axis and square-root y-axis.   

We find:

- Whe majority of vehicule rather timinh follow a rather smooth distribution that looks almost log-normal with a peak just short of 200 seconds, i.e. about 4 minutes.

- There are several suspiciously short rides with less than 10 seconds duration.

- Additionally, there is a strange delta-shaped peak of trip_duration just before the 1e5 seconds mark and even a few way above it:   
    
Plot density distribution the time to present to the place
```{r}
data %>%
  ggplot(aes(delta.departure.presentation)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```

We find:

- same smooth distribution that looks almost log-normal with a peak around 400, 500 seconds, i.e. about 6 minutes.

- Global variable : selection to arrival
around 8 to 10 mintues. 

- In many fire departments the measurement of turnout time and travel time are done manually. An officer presses a button located in the vehicle to signal his departure and his arrival. This process introduces irregularities and variation in the data, which will need to be cleaned. 



Box plots Ys 

For delta.selection.departure
```{r}
data %>% 
  ggplot(aes(delta.selection.departure)) +
  geom_boxplot() 
```

For delta.departure. presentation
```{r}
data %>% 
  ggplot(aes(delta.departure.presentation)) +
  geom_boxplot() 
```


Cor between Ys

```{r}

corr<-rcorr(as.matrix(y_train[,-c(1,4)])) # We remove global and ID which will be cor
y_train_cor= corr$r

corr
corrplot(y_train_cor, method="square",type="upper", order="hclust", tl.col="black", tl.srt=45)
```

The 2 Ys are not corr between them. 


### 2.2.1 Manage outliers for Ys values

Plot 
  delta.selection.departure
```{r}
y_train %>% 
  mutate(
      delta.selection.departure_minutes = round(delta.selection.departure / 60, 0),
    duration_grp = case_when(
      between(delta.selection.departure_minutes, 0,  2)  ~ "Less than 2 minutes",
      between(delta.selection.departure_minutes, 2, 4) ~ "2 to 4 minutes",
      between(delta.selection.departure_minutes, 4, 8) ~ "8 to 12 minutes",
      delta.selection.departure_minutes >= 8 ~ "8 or more minutes"
    ),
    duration_grp = factor(duration_grp, 
                          levels = c("Less than 2 minutes", "2 to 4 minutes", "8 to 12 minutes", "12 or more minutes"))
  ) %>%
  group_by(duration_grp) %>% 
  ggplot(aes(x=duration_grp,group=duration_grp)) + 
  geom_bar(fill="#E41A1C") +
  labs(x="Group", y="count") +
  theme_minimal()
```
Most of data is around 0 to 12 max minutes for delta.selection.departure. 


Departure to presentation
```{r}
y_train %>% 
  mutate(
      delta.departure.presentation_minutes = round(delta.departure.presentation / 60, 0),
    duration2_grp = case_when(
      between(delta.departure.presentation_minutes, 0,  5)  ~ "Less than 5 minutes",
      between(delta.departure.presentation_minutes, 5, 10) ~ "5 to 10 minutes",
      between(delta.departure.presentation_minutes, 10, 15) ~ "10 to 15 minutes",
      between(delta.departure.presentation_minutes, 15, 20) ~ "15 to 20 minutes",
      delta.departure.presentation_minutes >= 20 ~ " 20 or more minutes"
    ),
    duration2_grp = factor(duration2_grp, 
                          levels = c("Less than 5 minutes", "5 to 10 minutes", "10 to 15 minutes", "15 to 20 minutes","20 or more minutes" ))
  ) %>%
  group_by(duration2_grp) %>% 
  ggplot(aes(x=duration2_grp,group=duration2_grp)) + 
  geom_bar(fill="#E41A1C") +
  labs(x="Group", y="count") +
  theme_minimal()
```

Max 20 min

```{r}
y_train %>% 
  mutate(
      delta.selection.presentation_minutes = round(delta.selection.presentation / 60, 0),
    duration3_grp = case_when(
      between(delta.selection.presentation_minutes, 0,  5)  ~ "Less than 5 minutes",
      between(delta.selection.presentation_minutes, 5, 10) ~ "5 to 10 minutes",
      between(delta.selection.presentation_minutes, 10, 15) ~ "10 to 15 minutes",
      between(delta.selection.presentation_minutes, 15, 20) ~ "15 to 20 minutes",
      delta.selection.presentation_minutes >= 20 ~ " 20 or more minutes"
    ),
    duration3_grp = factor(duration3_grp, 
                          levels = c("Less than 5 minutes", "5 to 10 minutes", "10 to 15 minutes", "15 to 20 minutes","20 or more minutes" ))
  ) %>%
  group_by(duration3_grp) %>% 
  ggplot(aes(x=duration3_grp,group=duration3_grp)) + 
  geom_bar(fill="#E41A1C") +
  labs(x="Group", y="count") +
  theme_minimal()
```


=> Most of duration are between 0 to 20 min (1200 sec)
We can set our outlier cleaning


```{r}
data<- data[data$delta.selection.departure < 1200,]
data<-data[data$delta.departure.presentation < 1200,]
data<-data[data$delta.selection.presentation < 1200,]
```





### 2.2.2 Relation analysis between Y and other variables
In this part, we will first try to check if there is relation between our dependent variables and the dependent

Let's study  Y0 'selection-departure', Y1'departure-presentation',Y2'selection-presentation' vs feature vars

data and y without GPS data

```{r}
data.nogps<-data[,-c(21,20)]
```


We sample data in 3000 observations for scatter plot

```{r}
set.seed(1234)
foocor.all <- sample_n(data.nogps, 3000)
```

Let's use here scatter plot. Scatter plot are plotted along two axes, the pattern of the resulting points revealing any correlation present. One pattern of special interest is a linear pattern, where the data has a general look of a line going uphill or downhill. 


For instance, let's plot y0 vs alert.reason.category

```{r}
car::scatterplot(delta.selection.departure ~ OSRM.estimated.duration, data = foocor.all, 
                 smoother = TRUE, grid = TRUE)
```
Here we can see that there no clear linear correlation, maybe a some little smooth trend. 
But let's take delta. departure. presentation vs the OSRM estimated duration. 

```{r}
car::scatterplot(delta.departure.presentation~ OSRM.estimated.duration, data = foocor.all, 
                 smoother = TRUE, grid = TRUE)
```
We can observe a clear linear positive correlation. Normal since distance and time of presentation are correlated. 



Let's scatter plot matrix.  We just check the first lines for **ys vs other variables** for now and try to identify visually if there is some high independent explicative variable. 


Let's start by Y0 'selection-departure' 

Plot 5 first
```{r}
pairs(delta.selection.departure~.,data=foocor.all[,c(1,2,3,4,5,22)],
   main="Simple Scatterplot Matrix",lower.panel = NULL)

```

We find : 

It seems that we don't have clear linear correlation. Let's scatter plot the 5 next features. 

5 next
```{r}
pairs(delta.selection.departure~.,data=foocor.all[,c(6,7,8,9,10,11,22)],
   main="Simple Scatterplot Matrix",lower.panel = NULL)

```

Same conclusion. 

5 next

```{r}
pairs(delta.selection.departure~.,data=foocor.all[,c(12,13,14,15,16,17,22)],
   main="Simple Scatterplot Matrix",lower.panel = NULL)

```

Same conclusion. 




5 next
```{r}
pairs(delta.selection.departure~.,data=foocor.all[,c(18,19,20,21,22,23,24)],
   main="Simple Scatterplot Matrix",lower.panel = NULL)

```

Same conclusion. 

Here, We find that there is no clear visual linear relation between yo and other features. 

We will deeper our correlation analysis in the 4. part. 


Let's quickly check scatter plot matrix for delta.departure.presentation. 


```{r}
pairs(delta.departure.presentation~.,data=foocor.all[,c(1,2,3,4,5,23)],
   main="Simple Scatterplot Matrix",lower.panel = NULL)

```
Same conclusion.

```{r}
pairs(delta.departure.presentation~.,data=foocor.all[,c(6,7,8,9,10,11,23)],
   main="Simple Scatterplot Matrix",lower.panel = NULL)

```

Same conclusion

```{r}
pairs(delta.departure.presentation~.,data=foocor.all[,c(12,13,14,15,16,17,23)],
   main="Simple Scatterplot Matrix",lower.panel = NULL)

```
Same conclusion.

```{r}
pairs(delta.departure.presentation~.,data=foocor.all[,c(18,19,20,21,22,23)],
   main="Simple Scatterplot Matrix",lower.panel = NULL)

```

We find a linear correlation between y1 and OSRM estimated estimated time and distance (which seems to be normal). 

We will deeper our correlation analysis in the 4part of EDA. 

But first, let's manage outliers with some EDA with independant variables ! 


## 3. Explanatory data : Manage Outliers

### 3.1 Verify data outliers

#### 3.1.1 Quantitative Variables

##### 3.1.1.1 Histograms

```{r}
which(is.na(data.quanti)) #check for NA values before starting
```

```{r}
hist(data.quanti$longitude.intervention, col="blue",main="Longitude intervention")
```

```{r}
hist(data.quanti$latitude.intervention, col="blue",main="Latitude intervention")
```

```{r}
hist(data.quanti$delta.status.preceding.selection.selection, col="blue",main="delta status preceding selection-selection")
```

```{r}
hist(data.quanti$longitude.before.departure, col="blue",main="longitude before departure ")
```

```{r}
hist(data.quanti$latitude.before.departure, col="blue",main="Latitude before departure ")
```

```{r}
hist(data.quanti$OSRM.estimated.distance, col="blue",main="OSRM estimated distance")
```

```{r}
hist(data.quanti$OSRM.estimated.duration, col="blue",main="OSRM estimated duration")
```

##### 3.1.1.2 Plot Variables Density Distribution 

```{r}
data.quanti %>%
  ggplot(aes(longitude.intervention)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```


```{r}
data.quanti %>%
  ggplot(aes(latitude.intervention)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```


```{r}
data.quanti %>%
  ggplot(aes(delta.status.preceding.selection.selection)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```


```{r}
data.quanti %>%
  ggplot(aes(longitude.before.departure)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```


```{r}
data.quanti %>%
  ggplot(aes(latitude.before.departure)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```


```{r}
data.quanti %>%
  ggplot(aes(OSRM.estimated.distance)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```


```{r}
data.quanti %>%
  ggplot(aes(OSRM.estimated.duration)) +
  geom_density(fill = "red", bins = 100) +
  scale_x_log10() +
  scale_y_sqrt() + 
  theme_minimal()
```

##### 3.1.1.3 Boxplots

```{r}
boxplot(data.quanti$longitude.intervention, col="blue",main="Longitude intervention")
```

```{r}
boxplot(data.quanti$latitude.intervention, col="blue",main="Latitude intervention")
```

```{r}
boxplot(data.quanti$delta.status.preceding.selection.selection , col="blue",main="delta status preceding selection-selection")
```

```{r}
boxplot(data.quanti$longitude.before.departure, col="blue",main="longitude before departure")
```

```{r}
boxplot(data.quanti$latitude.before.departure, col="blue",main="latitude before departure")
```

```{r}
boxplot(data.quanti$OSRM.estimated.distance, col="blue",main="OSRM estimated distance")
```

```{r}
boxplot(data.quanti$OSRM.estimated.duration, col="blue",main="OSRM estimated duration")
```

##### 3.1.1.3 Manage Outliers 

```{r}
data.clean <- data[data$delta.status.preceding.selection.selection < 100000,]
data.clean <- data[data$OSRM.estimated.duration < 1000,]


#Assign the new value to data.quanti
colnames(data.clean)
data.quanti<-data.clean[,-c(3,4,5,6,7,10,11,12,15,17,24,25,26)]
data.quanti.y<-data.clean[,-c(3,4,5,6,7,10,11,12,15,17)]
```

#### 3.1.2 Qualitative Variables

##### 3.1.2.1 Tables 

```{r}
str(data.quali)
```

```{r}
table(data.quali$alert.reason.category)
prop.table(table(data.quali$alert.reason.category))
```

```{r}
table(data.quali$alert.reason) 
prop.table(table(data.quali$alert.reason))
```
According to the previous results, we need to combine several categories for the alert reason variable. However, we don't have enough information for grouping levels of that variable.

```{r}
table(data.quali$intervention.on.public.roads) 
prop.table(table(data.quali$intervention.on.public.roads))
```

```{r}
table(data.quali$floor) 
prop.table(table(data.quali$floor))
```
According to the previous results, we need to combine several categories for the floor variable.

```{r}
table(data.quali$location.of.the.event) 
prop.table(table(data.quali$location.of.the.event))
```
According to the previous results, we need to combine several categories for the alert reason variable. However, we don't have enough information for grouping levels of that variable.


```{r}
table(data.quali$emergency.vehicle)
prop.table(table(data.quali$emergency.vehicle))
```

```{r}
table(data.quali$emergency.vehicle.type)
prop.table(table(data.quali$emergency.vehicle.type))
```
According to the results, we need to combine several categories for the emergency vehicle type variable. 
However, we don't have enough information for grouping levels of that variable.

```{r}
table(data.quali$rescue.center)
prop.table(table(data.quali$rescue.center))
```
They are several levels which could be consider as outliers and we need to garbage them out. 

```{r}
table(data.quali$status.preceding.selection)
prop.table(table(data.quali$status.preceding.selection))
```
According to the results, we need to combine several categories for status preceding selection variable. 
However, we don't have enough information for grouping levels of that variable.

```{r}
table(data.quali$departed.from.its.rescue.center)
prop.table(table(data.quali$departed.from.its.rescue.center))
```

##### 3.1.2.2 Barplots 

```{r}
barplot(table(data.quali$alert.reason.category),horiz = F,cex.names=0.8,col="blue",main="Alert Reason Category",ylab="Frequency", plot=TRUE)
```

```{r}
barplot(table(data.quali$alert.reason),horiz = F,cex.names=0.8,col="blue",main="Alert Reason Category",ylab="Frequency", plot=TRUE)
```

```{r}
barplot(table(data.quali$intervention.on.public.roads),horiz = F,cex.names=0.8,col="blue",main="Intervention on public road",ylab="Frequency", plot=TRUE)
```

```{r}
barplot(table(data.quali$floor),horiz = F,cex.names=0.8,col="blue",main="Floors",ylab="Frequency", plot=TRUE)
```

```{r}
barplot(table(data.quali$location.of.the.event),horiz = F,cex.names=0.8,col="blue",main="Location of the event",ylab="Frequency", plot=TRUE)
```

```{r}
barplot(table(data.quali$emergency.vehicle),horiz = F,cex.names=0.8,col="blue",main="Emergency Vehicle Type",ylab="Frequency", plot=TRUE)
```


```{r}
barplot(table(data.quali$emergency.vehicle.type),horiz = F,cex.names=0.8,col="blue",main="Emergency Vehicle Type",ylab="Frequency", plot=TRUE)
```

```{r}
barplot(table(data.quali$rescue.center),horiz = F,cex.names=0.8,col="blue",main="Rescue center variable",ylab="Frequency", plot=TRUE)
```

```{r}
barplot(table(data.quali$status.preceding.selection),horiz = F,cex.names=0.8,col="blue",main="Emergency Vehicle Type",ylab="Frequency", plot=TRUE)
```

```{r}
barplot(table(data.quali$departed.from.its.rescue.center),horiz = F,cex.names=0.8,col="blue",main="Departed from its rescue center",ylab="Frequency", plot=TRUE)
```

##### 3.1.2.3 Group Together Categories With Low Frequency & Manage Outliers

for the floor variable, group everything below -2 & everything after 17
```{r}

table(data.clean$floor)

levels(data.clean$floor)<-list("-2"=c("-10","-9","-6","-5","-4","-3", "-2"),"-1"=c("-1"),"0"=c("0"),"1"=c("1"),"2"=c("2"),"3"=c("3"),"4"=c("4"),"5"=c("5"),"6"=c("6"),"7"=c("7"),"8"=c("8"),"9"=c("9"),"10"=c("10"),"11"=c("11"),"12"=c("12"),"13"=c("13"),"14"=c("14"),"15"=c("15"),"16"=c("16"),"17"=c("17","18","19","20","21","22","23","24","25","26","27","28","29", "30", "31", "32", "33", "37","52","79","100"))


table(data.clean$floor)

barplot(table(data.clean$floor),horiz = F,cex.names=0.8,col="blue",main="Floors",ylab="Frequency", plot=TRUE)

data.quali<-data.clean[,c(3,4,5,6,7,10,11,12,15,17)]
```

Apply same for x_test
```{r}

levels(x_test$floor)<-list("-2"=c("-10","-9","-6","-5","-4","-3", "-2"),"-1"=c("-1"),"0"=c("0"),"1"=c("1"),"2"=c("2"),"3"=c("3"),"4"=c("4"),"5"=c("5"),"6"=c("6"),"7"=c("7"),"8"=c("8"),"9"=c("9"),"10"=c("10"),"11"=c("11"),"12"=c("12"),"13"=c("13"),"14"=c("14"),"15"=c("15"),"16"=c("16"),"17"=c("17","18","19","20","21","22","23","24","25","26","27","28","29", "30", "31", "32", "33", "37","52","79","100"))


```


#### 3.1.2.4 Clean outliers for rescue.center



```{r}
table(data.quali$rescue.center)
```
We remove some levels (for data.clean$rescue.center variable) which are not significant for us because there are very few samples for them. 

table(data.clean$rescue.center)
levels(data.clean$rescue.center)



data.clean$rescue.center <- subset(data.clean$rescue.center, data.clean$rescue.center != "266281")


data.clean <- data.clean[data.clean$rescue.center != 266281,]

data.clean <- data.clean[data.clean$rescue.center != 266294,]

data.clean <- data.clean[data.clean$rescue.center != 266296,]

data.clean <- data.clean[data.clean$rescue.center != 266321,]

data.clean <- data.clean[data.clean$rescue.center != 266323,]

data.clean <- data.clean[data.clean$rescue.center != 266324,]

table(droplevels(data.clean$rescue.center))

table(data.clean$rescue.center)




### 3.2. What is time difference between departure.presentation and OSRM estimated duration ? 

Let's compute time difference between departure.presentation(actual) and OSRM estimated duration (predicted). 
This difference can't be taken into account in our future model. 
```{r}
time.diff<-data.clean$delta.departure.presentation-data.clean$OSRM.estimated.duration
time.diff %>% head
hist(time.diff, col="blue",main="Time diff")
summary(time.diff)
```
Here we can see that thre is a median 90 s (1min 30) of time diffirence between OSRM estimated duration and actual timing. 
One max at 1000 second. 
There is also min value which means that the brigate can also drive quickier than what OSRM predicted. 



## 4. Feature engineering

In this section we build new features from the existing ones, trying to find better predictors for our target variable. We prefer to define all these new features in a single code block below and then study them in the following subsections. 


### 4.1: Speed [km/h]

estimated speed by OSRM : distance / time

```{r}
data.fe<-data.clean
data.fe$OSRM.estimated.speed<-(data.clean$OSRM.estimated.distance/1000)/(data.clean$OSRM.estimated.duration/60^2)
data.fe$OSRM.estimated.speed %>% summary()
hist(data.fe$OSRM.estimated.speed , col="blue",main="Estimated Speed km/h")
```
Same for x_test
```{r}
x_test$OSRM.estimated.speed<-(x_test$OSRM.estimated.distance/1000)/(x_test$OSRM.estimated.duration/60^2)
```


#### 4.1.2 How top influencer predictors and estimated speed correlate ? 

```{r}
data.fe.sample <- sample_n(data.fe, 100)
```


```{r}
data.fe.sample %>%
  ggplot(aes(x=alert.reason, y=OSRM.estimated.speed,group=alert.reason)) +
  geom_boxplot()
```


```{r}
data.fe.sample %>%
  ggplot(aes(x=rescue.center, y=OSRM.estimated.speed)) +
  geom_boxplot()
```


```{r}
data.fe.sample %>%
  ggplot(aes(x=alert.reason.category, y=OSRM.estimated.speed)) +
  geom_boxplot()
```



### 4.2 Add month, day of week

```{r}
data.fe$month <-month(as.Date(as.character(data.fe$date.key.selection), "%Y%m%d"))

data.fe$weekdays <-weekdays(as.Date(as.character(data.fe$date.key.selection), "%Y%m%d"))
```
Same for x_test
```{r}
x_test$month <-month(as.Date(as.character(x_test$date.key.selection), "%Y%m%d"))

x_test$weekdays <-weekdays(as.Date(as.character(x_test$date.key.selection), "%Y%m%d"))
```


```{r}
data.fe$hours <-as.hms(formatC(as.integer(data.fe$time.key.selection), big.mark = ":", big.interval = 2L))

data.fe$hours <- replace(data.fe$hours, is.na(data.fe$hours), "00:00:00")
```

Same for x_test
```{r}
x_test$hours <-as.hms(formatC(as.integer(x_test$time.key.selection), big.mark = ":", big.interval = 2L))

x_test$hours <- replace(x_test$hours, is.na(x_test$hours), "00:00:00")
```

```{r}
data.fe$hours <- substr(data.fe$hours, 1, 2)
x_test$hours <- substr(x_test$hours, 1, 2)
```


```{r}
table(data.fe$month)
prop.table(table(data.fe$month))
```

```{r}
barplot(table(data.fe$month),horiz = F,cex.names=0.8,col="blue",main="Month",ylab="Frequency", plot=TRUE)
```

```{r}
table(data.fe$weekdays)
prop.table(table(data.fe$weekdays))
```

```{r}
barplot(table(data.fe$weekdays),horiz = F,cex.names=0.8,col="blue",main="Day",ylab="Frequency", plot=TRUE)
```


```{r}
table(data.fe$hours)
prop.table(table(data.fe$hours))
```

```{r}
barplot(table(data.fe$hours),horiz = F,cex.names=0.8,col="blue",main="Hours",ylab="Frequency", plot=TRUE)
```



We can now remove date.key.selection and time.key.selection

```{r}
data.fe<-data.fe[,-c(13,14)]

```
Same for x_test

```{r}
x_test<-x_test[,-c(13,14)]
```

Convert time and date build variables into factors

```{r}
data.fe$hours <- as.factor(data.fe$hours)
data.fe$weekdays <- as.factor(data.fe$weekdays)
data.fe$month <- as.factor(data.fe$month)

```

```{r}
x_test$hours <- as.factor(x_test$hours)
x_test$weekdays <- as.factor(x_test$weekdays)
x_test$month <- as.factor(x_test$month)

```

### 4.3 Order of the brigade


For the same event, multiple brigade can leave. 
It is worth to take into account that it might be a correlation between the order of the brigade to leave and the time for preparation. 
Once we have classify those brigade, we will be able to remove the id of the intervention. 


```{r}
data.fe$intervention %>% as.factor() %>% str
data.fe$emergency.vehicle.selection %>% str

204987-196480
```


```{r}
x_test$intervention %>% as.factor() %>% str
```


Plot frequency order of id intervention.


```{r}
a<-data.fe %>%
        group_by(intervention)%>%
         tally()
```

```{r}
b<-x_test %>%
        group_by(intervention)%>%
         tally()
```

```{r}
a %>% setDT
a %>% str
```

```{r}
b %>% setDT
```


```{r}
data.fe<-merge(a,data.fe, by.x = 'intervention', by.y = 'intervention', all=FALSE)
```

```{r}
x_test<-merge(b,x_test, by.x = 'intervention', by.y = 'intervention', all=FALSE)
```

Rename and convert as factor

```{r}
data.fe$n<-data.fe$n %>% as.factor
x_test$n<-x_test$n %>% as.factor
```
Now that we have intervention frequency as factor, we can remove intervention ID

```{r}
data.fe<-data.fe[,-c(1)]
x_test<-x_test[,-c(1)]
```



### 4.4 GPS
We decide to remove GPS data since we have the same data. 
```{r}
data.fe<-data.fe[,-c(18,19)]
x_test<-x_test[,-c(18,19)]
```

## 5. Correlation analysis

Update data.quanti and data.quali
```{r}
colnames(data.fe)

str(data.fe)

data.quanti<-data.fe[,c(23,22,19,18,17,16,14,9,8,2)]

data.quanti.y<-data.fe[,c(23,22,21,20,19,18,17,16,14,9,8,2)]

data.quali<-data.fe[,-c(23,22,21,20,19,18,17,16,14,9,8,2)]

data.quali.y<-data.fe[,-c(23,22,19,18,17,16,14,9,8,2)]

str(data.quanti)
str(data.quanti.y)
str(data.quali)
str(data.quali.y)

```


After engineering new features and before starting the modeling, we have to visualize the relations between our parameters using a correlation matrix. For this, we need to change all the factor features into a numerical format. The visualization uses the corrplot function from the eponymous package. Corrplot gives us great flexibility in manipulating the style of our plot.

What we see below, are the color-coded correlation coefficients for each combination of two features. In simplest terms: this shows whether two features are connected so that one changes with a predictable trend if you change the other. The closer this coefficient is to zero the weaker is the correlation. Both 1 and -1 are the ideal cases of perfect correlation and anti-correlation (dark blue and dark red in the plots below).

Here, we are of course interested if and how strongly our correlate with the ys. But we also want to know whether our potential predictors are correlated among each other, so that we can reduce the colinearity in our data set and improve the robustness of our prediction.


```{r}
data.fe %>%
  select(-emergency.vehicle.selection) %>%
  mutate(n = as.integer(n),
         alert.reason = as.integer(alert.reason),
         floor = as.integer(floor),
         emergency.vehicle = as.integer(emergency.vehicle),
         rescue.center = as.integer(rescue.center),
         delta.selection.presentation = as.integer(delta.selection.presentation),
         month = as.integer(month),
         hours = as.integer(hours),
        weekdays = as.integer(weekdays),
         alert.reason.category = as.integer(alert.reason.category),
         intervention.on.public.roads = as.integer(intervention.on.public.roads),
         location.of.the.event = as.integer(location.of.the.event),
         emergency.vehicle.type = as.integer(emergency.vehicle.type),
         status.preceding.selection = as.integer(status.preceding.selection),
          departed.from.its.rescue.center = as.integer(departed.from.its.rescue.center))%>%

  cor(use="complete.obs", method = "spearman") %>%
  corrplot(type="lower", method="pie",order="hclust", 
         diag=FALSE)

```
Add coefficients

```{r}
data.fe %>%
  select(-emergency.vehicle.selection) %>%
  mutate(n = as.integer(n),
         alert.reason = as.integer(alert.reason),
         floor = as.integer(floor),
         emergency.vehicle = as.integer(emergency.vehicle),
         rescue.center = as.integer(rescue.center),
         delta.selection.presentation = as.integer(delta.selection.presentation),
         month = as.integer(month),
         hours = as.integer(hours),
        weekdays = as.integer(weekdays),
         alert.reason.category = as.integer(alert.reason.category),
         intervention.on.public.roads = as.integer(intervention.on.public.roads),
         location.of.the.event = as.integer(location.of.the.event),
         emergency.vehicle.type = as.integer(emergency.vehicle.type),
         status.preceding.selection = as.integer(status.preceding.selection),
          departed.from.its.rescue.center = as.integer(departed.from.its.rescue.center))%>%

  cor(use="complete.obs", method = "spearman") %>%
  corrplot(type="lower", method="square",order="hclust", 
         addCoef.col = "black", diag=FALSE)

```

We find : 

- Alert reason is correlated to alert reason.category (0,65).
- OSRM estimated speed and OSRM distance are correlated (this is quite normal). We decide to keep the 2 features. 
- Status departure before selection and departed from its rescue center are perfectly correlated. We remove status departure before selection. 
- Longitude.before.departure and longitude.intervention are highly correlated. We can remove longitude.before.departure
- Latitude.before.departure and lat.intervention are highly correlated. We can remove lat.before.departure
- Except for ORSM features, there is no high correlated feature. 

```{r}
data.fe<-data.fe[,-c("alert.reason","status.preceding.selection","longitude.before.departure","latitude.before.departure")]
```

```{r}
x_test<-x_test[,-c("alert.reason","status.preceding.selection","longitude.before.departure","latitude.before.departure")]
```


## 6. Boosted Tree with XGB

Boosted Tree aka XGBoost. XGBoost is a well-known and efficient open source implementation of the improved gradient tree algorithm.  
Gradient boosting is a supervised learning algorithm, which attempts to accurately predict a target variable by combining estimates from a simpler and weaker set of models. GBoost reduces a regularized objective function (L1 and L2) that combines a convex loss function (based on the difference between predicted and target outputs) and a penalty condition for model complexity (in other words, regression tree functions).
Training continues iteratively, adding new trees that predict residuals or errors from previous trees that are then combined with the previous trees to make the final prediction.

In other words we are building a tree and looks which value is predicted poorly and assign to it higher weigh in our prediction.

Let us build and predict our model with 100 maximum number of boosting iterations.


### 6.1 Sample 

Store final dataset
```{r}
dataset<-data.fe
```


Sample data
```{r}
n_train <- round(0.8 * nrow(dataset))
train_indices <- sample(1:nrow(dataset), n_train)
trainset <- dataset[train_indices, ]
testset <- dataset[-train_indices, ]

```

### 6.2 Yo : Selection - Departure


Store only y0 target value
```{r}
trainset0_y0<-trainset$delta.selection.departure
trainset0<-trainset[,-c("delta.departure.presentation","delta.selection.presentation","delta.selection.departure")]
testset0_y0<-testset$delta.selection.departure
testset0<-testset[,-c("delta.departure.presentation","delta.selection.presentation","delta.selection.departure")]
```


Create one-hot matrix for cat variable. with sparse-matrix
```{r}
sparse_matrix <- sparse.model.matrix( ~ ., data = trainset0)[,-1]
```

Store into xgb Matrix
```{r}
dtrain1 <- xgb.DMatrix(sparse_matrix,label = trainset$delta.selection.departure)
```
Set parameters for our xgb tree
```{r}
xgb_params <- list(colsample_bytree = 0.7, #variables per tree 
                   subsample = 0.7, #data subset per tree 
                   booster = "gbtree",
                   max_depth = 5, #tree levels
                   eta = 0.3, #shrinkage
                   eval_metric = "rmse", 
                   objective = "reg:linear",
                   seed = 4321
                   )
```

train our model
```{r}
#set.seed(4321)
gb_0_dt <- xgb.train(params = xgb_params,
                   data = dtrain1,
                   print_every_n = 100,
                   nrounds = 100)
```
Plot the 30 first important features in our model

```{r}
importance_matrix <- xgb.importance(model = gb_0_dt)
xgb.plot.importance(importance_matrix[1:30,])
```
We find : 
- Delta statut preceding selection
- Hours
- Lat intervention
- Long internvetion
- emergency vehicule type VSAV$VD (group is or not)
- ORSRM data
- Rescue center 2474,77,75,2439  (group is or not)
- Alert-reason-cat-03
-departed from its rescue center1


Predict with testset0
```{r}
sparse_matrix2 <- sparse.model.matrix( ~ ., data =testset0 )[,-1]
```

Store into xgb Matrix


```{r}
dtest <- xgb.DMatrix(sparse_matrix2,label=testset$delta.selection.departure)
```

Predict

```{r}
pred_xgboost_y0 <- predict(gb_0_dt,dtest)
```

```{r}
pred_xgboost_y0 %>% head
testset$delta.selection.departure %>% head
```
Compute MSE, MAE, R2
```{r}
postResample(pred = pred_xgboost_y0, obs = testset$delta.selection.departure)

```



### 6.3 Y1 : Departure - Presentation

Store only y1 target value
```{r}
trainset1_y1<-trainset$delta.departure.presentation
trainset1<-trainset[,-c("delta.selection.departure","delta.selection.presentation","delta.departure.presentation")]
testset1_y1<-testset$delta.departure.presentation
testset1<-testset[,-c("delta.selection.departure","delta.selection.presentation","delta.departure.presentation")]
```

Create one-hot matrix for cat variable. with sparse-matrix
```{r}
sparse_matrix <- sparse.model.matrix( ~ ., data = trainset1)[,-1]
```

Store into xgb Matrix
```{r}
dtrain2 <- xgb.DMatrix(sparse_matrix,label = trainset$delta.departure.presentation)
```
Set parameters for our xgb tree
```{r}
xgb_params <- list(colsample_bytree = 0.5, #variables per tree 
                   subsample = 0.5, #data subset per tree 
                   booster = "gbtree",
                   max_depth = 3, #tree levels
                   eta = 0.3, #shrinkage
                   eval_metric = "rmse", 
                   objective = "reg:linear",
                   seed = 4321
                   )
```

train our model
```{r}
#set.seed(4321)
gb_1_dt <- xgb.train(params = xgb_params,
                   data = dtrain2,
                   print_every_n = 100,
                   nrounds = 100)
```
Plot the 30 first important features in our model

```{r}
importance_matrix <- xgb.importance(model = gb_1_dt)
xgb.plot.importance(importance_matrix[1:30,])
```
We find : 
- OSRM data
- Lat intervention
- Long internvetion
- statut.preceding-selection
- emergency vehicule type VSAV$VD (group is or not)


Predict
```{r}
sparse_matrix2 <- sparse.model.matrix( ~ ., data =testset1 )[,-1]
```

Store into xgb Matrix


```{r}
dtest <- xgb.DMatrix(sparse_matrix2,label=testset$delta.departure.presentation)
```

Predict

```{r}
pred_xgboost_y1 <- predict(gb_1_dt,dtest)
```

```{r}
pred_xgboost_y1 %>% head
testset$delta.departure.presentation %>% head
```
```{r}
postResample(pred = pred_xgboost_y1, obs = testset$delta.departure.presentation)
```



### 6.4 Ys : Compute global

```{r}
pred_xgboost_ys=pred_xgboost_y0+pred_xgboost_y1
pred_xgboost=data.frame(pred_xgboost_y0,pred_xgboost_y1,pred_xgboost_ys)

pred_xgboost %>% head
testset$delta.selection.presentation %>% head
```

```{r}
postResample(pred = pred_xgboost_ys, obs = testset$delta.departure.presentation)
```
No too bad accuracy ! 


### 6.5 Use feature importance to create group for factor variables for futur regression

For Y0 
```{r}
importance_matrix_y0 <- xgb.importance(model = gb_0_dt)
xgb.plot.importance(importance_matrix_y0[1:30,])
importance_matrix_y0[1:30,]
```
We find : 
- Delta status preceding selection
- Hours
- Lat intervention
- Long intervention
- emergency vehicle type VSAV$VD (group is or not)
- emergency.vehicle.typePSE
- emergency.vehicle.typeVID
- emergency.vehicle.typeCRF
- emergency.vehicle.typeFNPC
- ORSRM data
- Rescue center 2474,2477,2475,2439, 2435,2464, 2488, 2493(group is or not)
- Alert-reason-cat-03 -2
-departed from its rescue center1

We regroup the types of emergency vehicle, the rescue centers and the alert reason category
```{r}
trainset0.regroup <- trainset0
testset0.regroup <- testset0

trainset0.regroup = trainset0.regroup %>%
    mutate(emergency.vehicle.type.regroup = case_when(emergency.vehicle.type == "VSAV BSPP" ~  1,
                                  emergency.vehicle.type =="PSE" ~  1,
                                  emergency.vehicle.type == "VID" ~  1,
                                  emergency.vehicle.type == "CRF" ~  1,
                                  emergency.vehicle.type == "FNPC" ~  1,
                                  TRUE ~ 0))
trainset0.regroup = trainset0.regroup %>%
    mutate(rescue.center.regroup = case_when(rescue.center == "2474" ~  1,
                                  rescue.center =="2477" ~  1,
                                  rescue.center == "2475" ~  1,
                                  rescue.center == "2439" ~  1,
                                  rescue.center == "2435" ~  1,
                                  rescue.center == "2464" ~  1,
                                  rescue.center == "2488" ~  1,
                                  rescue.center == "2493" ~  1,
                                  TRUE ~ 0))


testset0.regroup = testset0.regroup %>%
    mutate(emergency.vehicle.type.regroup = case_when(emergency.vehicle.type == "VSAV BSPP" ~  1,
                                  emergency.vehicle.type =="PSE" ~  1,
                                  emergency.vehicle.type == "VID" ~  1,
                                  emergency.vehicle.type == "CRF" ~  1,
                                  emergency.vehicle.type == "FNPC" ~  1,
                                  TRUE ~ 0))
testset0.regroup = testset0.regroup  %>%
    mutate(rescue.center.regroup = case_when(rescue.center == "2474" ~  1,
                                  rescue.center =="2477" ~  1,
                                  rescue.center == "2475" ~  1,
                                  rescue.center == "2439" ~  1,
                                  rescue.center == "2435" ~  1,
                                  rescue.center == "2464" ~  1,
                                  rescue.center == "2488" ~  1,
                                  rescue.center == "2493" ~  1,
                                  TRUE ~ 0))



  
```


Drop not-important features in trainset0


```{r}
trainset0.regroup$rescue.center<-NULL
trainset0.regroup$n<-NULL
trainset0.regroup$emergency.vehicle.type<-NULL
trainset0.regroup$floor<-NULL
trainset0.regroup$emergency.vehicle<-NULL
trainset0.regroup$weekdays<-NULL
trainset0.regroup$intervention.on.public.roads<-NULL
trainset0.regroup$location.of.the.event<-NULL
trainset0.regroup$month<-NULL
```


```{r}
testset0.regroup$rescue.center<-NULL
testset0.regroup$emergency.vehicle.type<-NULL

testset0.regroup$n<-NULL
testset0.regroup$floor<-NULL
testset0.regroup$emergency.vehicle<-NULL
testset0.regroup$weekdays<-NULL
testset0.regroup$intervention.on.public.roads<-NULL
testset0.regroup$location.of.the.event<-NULL
testset0.regroup$month<-NULL
```



For Y1
```{r}
importance_matrix_y1 <- xgb.importance(model = gb_1_dt)
xgb.plot.importance(importance_matrix_y1[1:30,])
importance_matrix_y1[1:30,]
```
We find : 
- OSRM data
- Lat intervention
- Long intervention
- status.preceding-selection
- emergency.vehicle.typeVID
- emergency.vehicle.typePSE
- emergency.vehicle.typeCRF
- rescue.center2506, 2507, 2485, 2481, 2498, 2500
- emergency.vehicle.typeVSAV BSPP
- emergency.vehicle.typeFPT BSPP
- alert.reason.category6
- location.of.the.event139, 136, 259

```{r}
trainset1.regroup <- trainset1
testset1.regroup <- testset1

trainset1.regroup = trainset1.regroup %>%
    mutate(emergency.vehicle.type.regroup = case_when(emergency.vehicle.type == "VSAV BSPP" ~  1,
                                  emergency.vehicle.type =="FPT BSPP" ~  1,
                                  emergency.vehicle.type == "VID" ~  1,
                                  emergency.vehicle.type == "CRF" ~  1,
                                  emergency.vehicle.type == "PSE" ~  1,
                                  TRUE ~ 0))

trainset1.regroup = trainset1.regroup %>%
    mutate(rescue.center.regroup = case_when(rescue.center == "2506" ~  1,
                                  rescue.center =="2507" ~  1,
                                  rescue.center == "2485" ~  1,
                                  rescue.center == "2481" ~  1,
                                  rescue.center == "2498" ~  1,
                                  rescue.center == "2500" ~  1,
                                  TRUE ~ 0))
trainset1.regroup = trainset1.regroup %>%
    mutate(location.of.the.event.regroup = case_when(location.of.the.event == "2506" ~  1,
                                  location.of.the.event =="139" ~  1,
                                  location.of.the.event == "136" ~  1,
                                  rescue.center == "259" ~  1,
                                  TRUE ~ 0))

testset1.regroup = testset1.regroup %>%
    mutate(emergency.vehicle.type.regroup = case_when(emergency.vehicle.type == "VSAV BSPP" ~  1,
                                  emergency.vehicle.type =="FPT BSPP" ~  1,
                                  emergency.vehicle.type == "VID" ~  1,
                                  emergency.vehicle.type == "CRF" ~  1,
                                  emergency.vehicle.type == "PSE" ~  1,
                                  TRUE ~ 0))

testset1.regroup = testset1.regroup %>%
    mutate(rescue.center.regroup = case_when(rescue.center == "2506" ~  1,
                                  rescue.center =="2507" ~  1,
                                  rescue.center == "2485" ~  1,
                                  rescue.center == "2481" ~  1,
                                  rescue.center == "2498" ~  1,
                                  rescue.center == "2500" ~  1,
                                  TRUE ~ 0))
testset1.regroup = testset1.regroup%>%
    mutate(location.of.the.event.regroup = case_when(location.of.the.event == "2506" ~  1,
                                  location.of.the.event =="139" ~  1,
                                  location.of.the.event == "136" ~  1,
                                  rescue.center == "259" ~  1,
                                  TRUE ~ 0))


```

Drop not important features
```{r}
trainset1.regroup$rescue.center<-NULL
trainset1.regroup$emergency.vehicle.type<-NULL
trainset1.regroup$location.of.the.event<-NULL
trainset1.regroup$emergency.vehicle<-NULL
trainset1.regroup$departed.from.its.rescue.center<-NULL


```

```{r}
testset1.regroup$rescue.center<-NULL
testset1.regroup$emergency.vehicle.type<-NULL
testset1.regroup$location.of.the.event<-NULL
testset1.regroup$emergency.vehicle<-NULL
testset1.regroup$departed.from.its.rescue.center<-NULL
```



## 6. OLS - Regression


### 6.1 Yo : Selection - Departure

Remove id variable

```{r}
trainset0.regroup<-trainset0.regroup[,-c("emergency.vehicle.selection")]
trainset0.regroup$delta.selection.departure<-trainset$delta.selection.departure

```

```{r}
testset0.regroup<-testset0.regroup[,-c("emergency.vehicle.selection")]
testset0.regroup$delta.selection.departure<-testset$delta.selection.departure

```

Same x_test
```{r}
x_test0.regroup<-x_test0.regroup[,-c("emergency.vehicle.selection")]
```


```{r}
#Linear Regression,

options(max.print = 10000)

lm <- lm(delta.selection.departure ~.,data = trainset0.regroup)

summary(lm)


```

All our coef are significants. We will check hypothesis in 6.2.3. 


#### 6.1.2 Y0 : Multicolinéarity 

```{r}
library(sandwich)
library(car)

vif(lm)
```
Except for OSRM data, no high correlated coefficient. We decide to keep them as they are important for our model. 




#### 6.1.3 Residuals analysis

Study the residuals of the selected model
What we've done is not enough to validate the model. We need to study the residuals
if hypothesis are not validated (see course.), the test of the coefficient are false 
Study the residuals of the selected model

##### 6.1.3.1 Is residuals means 0?

```{r}
#mean of residuals
summary(lm$residuals) 
```
Yes it is !

##### 6.1.3.2 Are residuals normally distributed?

Normality test : shapiro test
H0 : Normality and H1 : no normality
```{r}
library(tseries)
jarque.bera.test(lm$residuals)

```
No normality because p-value is << 5%. Here, residuals are not normally distributed. 
NB : non normality could appear because of outliers. 

```{r}
qqnorm(lm$residuals)
qqline(lm$residuals)
```

##### 6.1.3.3 Are residuals homoskedastic?

1. First model which is not considering heteroskedasticity

```{r}

plot(lm$residuals~lm$fitted)

library(lmtest)

# Breush Pagan test H0 : homoskedasticity against H1 : heteroskedasticity 

bptest(lm)

```
pvalue << 5%, we reject H0
residuals are heteroskedastic

In case of heteroskedasticity, we have to use a robust standard error estimator. Otherwise, all our t-tests will be wrong.


2. Second model taking into account heteroskedasticity

We calculate the robust covariance matrix
```{r}
library(sandwich)
vcov_y0 <- vcovHC(lm, type = "HC1")
coeftest(lm, vcov. = vcov_y0)
```
The estimated value of the coefficients remains, coefficients are still significant with this model 


##### 6.2.3.4 Are the residuals correlated ?

There are several tests for autocorrelation
Durbin-Watson test is one of the most often used

H0 : Residuals are non autocorrelated
H1 : Residuals are autocorrelated

1. First model which is not considering heteroskedasticity

We can't use the Durbin-Waston test since the size of our linear regression

2. Second model taking into account heteroskedasticity

```{r}

library(sandwich)

#Calculate the robust covariance matrix

vcov_y0_2 <- NeweyWest(lm)

coeftest(lm, vcov. = vcov_y0_2)
```
The estimated value of the coefficients remains, coefficients are still significant with this model. 


#### 6.1.4 Y0 : Prediction


```{r}
pred_reg_y0 <- predict(lm,testset0.regroup)
```

```{r}
pred_reg_y0 %>% head
testset$delta.selection.departure %>% head
```

Compute R2
```{r}
postResample(pred = pred_reg_y0, obs = testset0.regroup$delta.selection.departure)

```


Pred for x_0

```{r}
pred_reg_final_y0 <- predict(lm,x_test0.regroup)
```



### 6.2 Y1 

Remove id variable

```{r}
trainset1.regroup<-trainset1.regroup[,-c("emergency.vehicle.selection")]
trainset1.regroup$delta.departure.presentation<-trainset$delta.departure.presentation

```

```{r}
testset1.regroup<-testset1.regroup[,-c("emergency.vehicle.selection")]
testset1.regroup$delta.departure.presentation<-testset$delta.departure.presentation

```
Same x_test
```{r}
x_test1.regroup<-x_test1.regroup[,-c("emergency.vehicle.selection")]
```




```{r}
#Linear Regression,

options(max.print = 10000)

lm1 <- lm(delta.departure.presentation ~.,data = trainset1.regroup)


summary(lm1)


```
All our coefficients are significants 
#### 6.2.2 Y1 : Multicolinéarity 

```{r}
library(sandwich)
library(car)

vif(lm1)

#variables qualitatives 

```
Except for OSRM data, no high correlated coefficient. We decide to keep them as they are important for our model. 

#### 6.2.3 Y1 : Residuals analysis

Study the residuals of the selected model
What we've done is not enough to validate the model. We need to study the residuals
if hypothesis are not validated (see course.), the test of the coefficient are false 
Study the residuals of the selected model

##### 6.2.3.1 Is residuals means 0?

```{r}
#mean of residuals
summary(lm1$residuals) 
```
Yes it is !

##### 6.2.3.2 Are residuals normally distributed?

Normality test : shapiro test
H0 : Normality and H1 : no normality
```{r}
library(tseries)

jarque.bera.test(lm1$residuals)


#install.packages("nortest")
library(nortest)
ad.test(lm1$residuals)


```
No normality because p-value is << 5%. Here, residuals are not normally distributed. 
NB : non normality could appear because of outliers. 

```{r}

qqnorm(lm1$residuals)
qqline(lm1$residuals)

```

##### 6.2.3.3 Are residuals homoskedastic?

1. First model which is not considering heteroskedasticity

```{r}

plot(lm1$residuals~lm$fitted)

library(lmtest)

# Breush Pagan test H0 : homoskedasticity against H1 : heteroskedasticity 

bptest(lm1)

```
pvalue << 5%, we reject H0
residuals are heteroskedastic

In case of heteroskedasticity, we have to use a robust standard error estimator. Otherwise, all our t-tests will be wrong.


2. Second model taking into account heteroskedasticity

```{r}

library(sandwich)

#Calculate the robust covariance matrix

vcov_y1 <- vcovHC(lm1, type = "HC1")

coeftest(lm, vcov. = vcov_y1)
```
The estimated value of the coefficients remains, coefficients are still significant with this model 

##### 6.2.3.4 Are the residuals correlated ?

1. First model taking into account heteroskedasticity

```{r}

library(sandwich)

#Calculate the robust covariance matrix

vcov_y1_2 <- NeweyWest(lm1)

coeftest(lm1, vcov. = vcov_y1_2)
```
The estimated value of the coefficients remains, coefficients are still significant with this model 

### 6.3.4 Y1 : Prediction


```{r}
pred_reg_y1 <- predict(lm1,testset1.regroup)
```

```{r}
pred_reg_y1 %>% head
testset$delta.departure.presentation %>% head
```

Compute MSE
```{r}
postResample(pred = pred_reg_y1, obs = testset1.regroup$delta.departure.presentation)

```


#### Pred for x_1

```{r}
testset1.regroup %>% str
x_test1.regroup %>% str
```

```{r}
pred_reg_final_y1 <- predict(lm1,x_test1.regroup)
```

New levels in x_test

```{r}
testset1.regroup$n %>% levels
x_test1.regroup$n %>% levels
```


Re_train model without n-levels

```{r}
#Linear Regression,

options(max.print = 10000)

lm1 <- lm(delta.departure.presentation ~.,data = trainset1.regroup[,-c("n")])


summary(lm1)


```
```{r}
pred_reg_final_y1 <- predict(lm1,x_test1.regroup[,-c("n")])

```


### 6.4 Ys : Compute global

```{r}
pred_reg_ys=pred_reg_y0+pred_reg_y1
pred_reg=data.frame(pred_reg_y0,pred_reg_y1,pred_reg_ys)

pred_reg %>% head
testset$delta.selection.presentation %>% head
```

```{r}
postResample(pred = pred_reg_ys, obs = testset$delta.departure.presentation)
```
No too bad accuracy ! 



### 7. Actual predict : Compute Global for x_test

```{r}
pred_reg_final_ys=pred_reg_final_y0+pred_reg_final_y1
pred_final=data.frame(pred_reg_final_y0,pred_reg_final_y1,pred_reg_final_ys)
pred_final %>% head
```





```{r}
pred_final$id<-x_test$emergency.vehicle.selection
```
Change order
```{r}
pred_final <- pred_final[, c(4, 1, 2, 3)]

```

Conver into integer
```{r}
pred_final$pred_reg_final_y0=pred_final$pred_reg_final_y0 %>% as.integer()
pred_final$pred_reg_final_y1=pred_final$pred_reg_final_y1 %>% as.integer()
pred_final$pred_reg_final_ys=pred_final$pred_reg_final_ys %>% as.integer
```



Retrieve Order from challange
```{r}
order_x_test<-read.csv("x_test.csv")
order_x_test<-data.frame(order_x_test$emergency.vehicle.selection)

order_x_test %>% setDT
order_x_test %>% head

y_final<-merge(order_x_test,pred_final, by.x = 'order_x_test.emergency.vehicle.selection', by.y = 'emergency-vehicle-selection', all = FALSE,sort=FALSE)
```


```{r}
y_final %>% str
```

```{r}
sum(is.na(y_final))
which(is.na(y_final))
y_final[is.na(y_final)] <- 0
```


```{r}
fwrite(y_final, "y_test.csv",sep=",")
```

## 8. Contributors



Liens notebook inspiration artistique : 
Les notebooks qui ont déja fait le challenge : 
https://github.com/quachn/X_PFB
https://github.com/Gguinet/Fire-Brigade-Challenge/blob/master/.ipynb_checkpoints/Code-checkpoint.ipynb




Les notebooks traitant du même type de problème : 
https://medium.com/crim/predicting-the-response-times-of-firefighters-using-data-science-da79f6965f93
https://www.kaggle.com/gaborfodor/from-eda-to-the-top-lb-0-367
https://www.kaggle.com/karelrv/nyct-from-a-to-z-with-xgboost-tutorial
https://www.kaggle.com/headsortails/nyc-taxi-eda-update-the-fast-the-curious

